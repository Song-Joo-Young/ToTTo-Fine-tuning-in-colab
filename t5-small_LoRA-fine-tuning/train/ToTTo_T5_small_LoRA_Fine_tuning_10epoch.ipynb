{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRiIL3GkTTA0"
      },
      "source": [
        "## **T5-small LoRA Fine-tuning on ToTTo**\n",
        "\n",
        "From : [JooYoung Song](https://github.com/Song-Joo-Young/ToTTo-Fine-tuning-in-colab/tree/main)\n",
        "\n",
        "Code Reference :\n",
        "* PEFT : https://huggingface.co/docs/peft/main/en/index\n",
        "* ToTTo : https://github.com/google-research-datasets/ToTTo\n",
        "* Prompt-Tuning-on-ToTTo : https://github.com/ChainsmokersAI/Prompt-Tuning-on-ToTTo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgHe6df5gl9I",
        "outputId": "266536ad-e49f-4c73-f7b0-25c4488b1b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Drive Mount\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsYkg24SX36S",
        "outputId": "557ecabb-daf1-4154-da87-0593a2611d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-06 07:54:38--  https://storage.googleapis.com/totto-public/totto_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 2607:f8b0:4023:c0b::cf, 2607:f8b0:4023:c0d::cf, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 187724372 (179M) [application/zip]\n",
            "Saving to: ‘totto_data.zip’\n",
            "\n",
            "totto_data.zip      100%[===================>] 179.03M  59.4MB/s    in 3.0s    \n",
            "\n",
            "2024-02-06 07:54:41 (59.4 MB/s) - ‘totto_data.zip’ saved [187724372/187724372]\n",
            "\n",
            "Archive:  totto_data.zip\n",
            "  inflating: totto_data/totto_dev_data.jsonl  \n",
            "  inflating: totto_data/totto_train_data.jsonl  \n",
            "  inflating: totto_data/unlabeled_totto_test_data.jsonl  \n"
          ]
        }
      ],
      "source": [
        "# Get Dataset\n",
        "\n",
        "!wget https://storage.googleapis.com/totto-public/totto_data.zip\n",
        "!unzip totto_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HSDPyw28Xclb",
        "outputId": "1c3fdc39-e989-4de9-bfd2-124ad9285eec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ToTTo_data'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 드라이브에 데이터셋 저장 추후 가중치도 저장할 폴더\n",
        "# Copy Dataset to your Google Drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "source_folder = '/content/totto_data'\n",
        "destination_folder = '/content/drive/MyDrive/ToTTo_data'\n",
        "\n",
        "if os.path.exists(destination_folder):\n",
        "    shutil.rmtree(destination_folder)\n",
        "\n",
        "shutil.copytree(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SifiwLhvTfAL"
      },
      "source": [
        "### **1. Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJOHz_ZYCiOV",
        "outputId": "85c6dea8-5cd6-4cc7-f394-56a4577f9533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting peft\n",
            "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: dill, responses, multiprocess, accelerate, datasets, peft, evaluate\n",
            "Successfully installed accelerate-0.26.1 datasets-2.16.1 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 peft-0.8.2 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets sentencepiece peft accelerate evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73SN1-ioXipz",
        "outputId": "9495b2e3-e0a8-4bca-db28-01a7a15ab0e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120761"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Load Train Set\n",
        "# with open('/content/totto_data/totto_train_data.jsonl', 'r') as f:\n",
        "with open('/content/drive/MyDrive/ToTTo_data/totto_train_data.jsonl', 'r') as f:\n",
        "    data_train=f.read().splitlines()\n",
        "    f.close()\n",
        "\n",
        "# Number of Train Data\n",
        "len(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3iIU_s2CliG",
        "outputId": "9026dc7a-a33d-4e51-eb14-d0a7751f2735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ table \n",
            " \t  [[{'value': 'Rank', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Lane', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Name', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Nationality', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Time', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Notes', 'is_header': True, 'column_span': 1, 'row_span': 1}], [{'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '4', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Matt Grevers', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'United States', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '52.16', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'OR', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '2', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Nick Thoman', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'United States', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '52.92', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '6', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Ryosuke Irie', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Japan', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '52.97', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '4', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '5', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Camille Lacourt', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'France', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.08', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '5', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '3', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Liam Tancock', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Great Britain', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.35', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '6', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '1', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Helge Meeuw', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Germany', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.48', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '7', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '8', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Hayden Stoeckel', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Australia', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.55', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '8', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '7', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Cheng Feiyi', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'China', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.77', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}]]\n",
            "→ table_webpage_url \n",
            " \t  http://en.wikipedia.org/wiki/Swimming_at_the_2012_Summer_Olympics_%E2%80%93_Men's_100_metre_backstroke\n",
            "→ table_page_title \n",
            " \t  Swimming at the 2012 Summer Olympics – Men's 100 metre backstroke\n",
            "→ table_section_title \n",
            " \t  Final\n",
            "→ table_section_text \n",
            " \t  \n",
            "→ highlighted_cells \n",
            " \t  [[4, 0], [4, 2], [4, 4]]\n",
            "→ example_id \n",
            " \t  -2235792344822110317\n",
            "→ sentence_annotations \n",
            " \t  [{'original_sentence': 'Leading the race early on the initial length, Lacourt dropped off the podium to a fourth-place time in 53.08.', 'sentence_after_deletion': 'Lacourt dropped to a fourth-place time in 53.08.', 'sentence_after_ambiguity': 'Lacourt was dropped to a fourth-place time in 53.08.', 'final_sentence': 'Lacourt was dropped to a fourth-place time in 53.08.'}]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Sample Data\n",
        "data_sample=json.loads(data_train[-1])\n",
        "\n",
        "# Key-Value Set\n",
        "for key, value in data_sample.items():\n",
        "    # if key=='table': continue\n",
        "\n",
        "    print('→', key, '\\n \\t ', value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tHA8DvraYjJs"
      },
      "outputs": [],
      "source": [
        "# Google's Official Preprocess Codes\n",
        "# https://github.com/google-research/language/blob/master/language/totto/baseline_preprocessing/preprocess_utils.py\n",
        "\n",
        "import copy\n",
        "\n",
        "def _add_adjusted_col_offsets(table):\n",
        "  \"\"\"Add adjusted column offsets to take into account multi-column cells.\"\"\"\n",
        "  adjusted_table = []\n",
        "  for row in table:\n",
        "    real_col_index = 0\n",
        "    adjusted_row = []\n",
        "    for cell in row:\n",
        "      adjusted_cell = copy.deepcopy(cell)\n",
        "      adjusted_cell[\"adjusted_col_start\"] = real_col_index\n",
        "      adjusted_cell[\"adjusted_col_end\"] = (\n",
        "          adjusted_cell[\"adjusted_col_start\"] + adjusted_cell[\"column_span\"])\n",
        "      real_col_index += adjusted_cell[\"column_span\"]\n",
        "      adjusted_row.append(adjusted_cell)\n",
        "    adjusted_table.append(adjusted_row)\n",
        "  return adjusted_table\n",
        "\n",
        "\n",
        "def _get_heuristic_row_headers(adjusted_table, row_index, col_index):\n",
        "  \"\"\"Heuristic to find row headers.\"\"\"\n",
        "  row_headers = []\n",
        "  row = adjusted_table[row_index]\n",
        "  for i in range(0, col_index):\n",
        "    if row[i][\"is_header\"]:\n",
        "      row_headers.append(row[i])\n",
        "  return row_headers\n",
        "\n",
        "\n",
        "def _get_heuristic_col_headers(adjusted_table, row_index, col_index):\n",
        "  \"\"\"Heuristic to find column headers.\"\"\"\n",
        "  adjusted_cell = adjusted_table[row_index][col_index]\n",
        "  adjusted_col_start = adjusted_cell[\"adjusted_col_start\"]\n",
        "  adjusted_col_end = adjusted_cell[\"adjusted_col_end\"]\n",
        "  col_headers = []\n",
        "  for r in range(0, row_index):\n",
        "    row = adjusted_table[r]\n",
        "    for cell in row:\n",
        "      if (cell[\"adjusted_col_start\"] < adjusted_col_end and\n",
        "          cell[\"adjusted_col_end\"] > adjusted_col_start):\n",
        "        if cell[\"is_header\"]:\n",
        "          col_headers.append(cell)\n",
        "\n",
        "  return col_headers\n",
        "\n",
        "\n",
        "def get_highlighted_subtable(table, cell_indices, with_heuristic_headers=False):\n",
        "  \"\"\"Extract out the highlighted part of a table.\"\"\"\n",
        "  highlighted_table = []\n",
        "\n",
        "  adjusted_table = _add_adjusted_col_offsets(table)\n",
        "\n",
        "  for (row_index, col_index) in cell_indices:\n",
        "    cell = table[row_index][col_index]\n",
        "    if with_heuristic_headers:\n",
        "      row_headers = _get_heuristic_row_headers(adjusted_table, row_index,\n",
        "                                               col_index)\n",
        "      col_headers = _get_heuristic_col_headers(adjusted_table, row_index,\n",
        "                                               col_index)\n",
        "    else:\n",
        "      row_headers = []\n",
        "      col_headers = []\n",
        "\n",
        "    highlighted_cell = {\n",
        "        \"cell\": cell,\n",
        "        \"row_headers\": row_headers,\n",
        "        \"col_headers\": col_headers\n",
        "    }\n",
        "    highlighted_table.append(highlighted_cell)\n",
        "\n",
        "  return highlighted_table\n",
        "\n",
        "\n",
        "def linearize_full_table(table, cell_indices, table_page_title,\n",
        "                         table_section_title):\n",
        "  \"\"\"Linearize full table with localized headers and return a string.\"\"\"\n",
        "  table_str = \"\"\n",
        "  if table_page_title:\n",
        "    table_str += \"<page_title> \" + table_page_title + \" </page_title> \"\n",
        "  if table_section_title:\n",
        "    table_str += \"<section_title> \" + table_section_title + \" </section_title> \"\n",
        "\n",
        "  table_str += \"<table> \"\n",
        "  adjusted_table = _add_adjusted_col_offsets(table)\n",
        "  for r_index, row in enumerate(table):\n",
        "    row_str = \"<row> \"\n",
        "    for c_index, col in enumerate(row):\n",
        "\n",
        "      row_headers = _get_heuristic_row_headers(adjusted_table, r_index, c_index)\n",
        "      col_headers = _get_heuristic_col_headers(adjusted_table, r_index, c_index)\n",
        "\n",
        "      # Distinguish between highlighted and non-highlighted cells.\n",
        "      if [r_index, c_index] in cell_indices:\n",
        "        start_cell_marker = \"<highlighted_cell> \"\n",
        "        end_cell_marker = \"</highlighted_cell> \"\n",
        "      else:\n",
        "        start_cell_marker = \"<cell> \"\n",
        "        end_cell_marker = \"</cell> \"\n",
        "\n",
        "      # The value of the cell.\n",
        "      item_str = start_cell_marker + col[\"value\"] + \" \"\n",
        "\n",
        "      # All the column headers associated with this cell.\n",
        "      for col_header in col_headers:\n",
        "        item_str += \"<col_header> \" + col_header[\"value\"] + \" </col_header> \"\n",
        "\n",
        "      # All the row headers associated with this cell.\n",
        "      for row_header in row_headers:\n",
        "        item_str += \"<row_header> \" + row_header[\"value\"] + \" </row_header> \"\n",
        "\n",
        "      item_str += end_cell_marker\n",
        "      row_str += item_str\n",
        "\n",
        "    row_str += \"</row> \"\n",
        "    table_str += row_str\n",
        "\n",
        "  table_str += \"</table>\"\n",
        "  if cell_indices:\n",
        "    assert \"<highlighted_cell>\" in table_str\n",
        "  return table_str\n",
        "\n",
        "\n",
        "def linearize_subtable(subtable, table_page_title, table_section_title):\n",
        "  \"\"\"Linearize the highlighted subtable and return a string of its contents.\"\"\"\n",
        "  table_str = \"\"\n",
        "  if table_page_title:\n",
        "    table_str += \"<page_title> \" + table_page_title + \" </page_title> \"\n",
        "  if table_section_title:\n",
        "    table_str += \"<section_title> \" + table_section_title + \" </section_title> \"\n",
        "  table_str += \"<table> \"\n",
        "\n",
        "  for item in subtable:\n",
        "    cell = item[\"cell\"]\n",
        "    row_headers = item[\"row_headers\"]\n",
        "    col_headers = item[\"col_headers\"]\n",
        "\n",
        "    # The value of the cell.\n",
        "    item_str = \"<cell> \" + cell[\"value\"] + \" \"\n",
        "\n",
        "    # All the column headers associated with this cell.\n",
        "    for col_header in col_headers:\n",
        "      item_str += \"<col_header> \" + col_header[\"value\"] + \" </col_header> \"\n",
        "\n",
        "    # All the row headers associated with this cell.\n",
        "    for row_header in row_headers:\n",
        "      item_str += \"<row_header> \" + row_header[\"value\"] + \" </row_header> \"\n",
        "\n",
        "    item_str += \"</cell> \"\n",
        "    table_str += item_str\n",
        "\n",
        "  table_str += \"</table>\"\n",
        "  return table_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkf__eetM00D",
        "outputId": "f67c7148-c5e5-49b4-a0e3-9724001c5f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Highlighted Cells\n",
            "{'value': '4', 'is_header': False, 'column_span': 1, 'row_span': 1}\n",
            "{'value': 'Camille Lacourt', 'is_header': False, 'column_span': 1, 'row_span': 1}\n",
            "{'value': '53.08', 'is_header': False, 'column_span': 1, 'row_span': 1}\n",
            "\n",
            "→ Linearized (Preprocessed) Cells\n",
            "<page_title> Swimming at the 2012 Summer Olympics – Men's 100 metre backstroke </page_title> <section_title> Final </section_title> <table> <cell> 4 <col_header> Rank </col_header> </cell> <cell> Camille Lacourt <col_header> Name </col_header> </cell> <cell> 53.08 <col_header> Time </col_header> </cell> </table>\n",
            "\n",
            "→ Final (Label) Sentence\n",
            "Lacourt was dropped to a fourth-place time in 53.08.\n"
          ]
        }
      ],
      "source": [
        "# from preprocess_utils import get_highlighted_subtable, linearize_subtable\n",
        "\n",
        "print('→', 'Highlighted Cells')\n",
        "for (index_row, index_col) in data_sample['highlighted_cells']:\n",
        "    print(data_sample['table'][index_row][index_col])\n",
        "\n",
        "print('\\n→', 'Linearized (Preprocessed) Cells')\n",
        "subtable=get_highlighted_subtable(table=data_sample['table'], cell_indices=data_sample['highlighted_cells'], with_heuristic_headers=True)\n",
        "cells_linearized=linearize_subtable(\n",
        "    subtable=subtable,\n",
        "    table_page_title=data_sample['table_page_title'],\n",
        "    table_section_title=data_sample['table_section_title']\n",
        ")\n",
        "print(cells_linearized)\n",
        "\n",
        "print('\\n→', 'Final (Label) Sentence')\n",
        "for sentence in data_sample['sentence_annotations']:\n",
        "    print(sentence['final_sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300,
          "referenced_widgets": [
            "d4f8af11c74d4e269d8ec3bed6cfd7f3",
            "afd05d0d61a442948f3b253e09d37988",
            "989f28293b734a8baa4453926577793b",
            "de16466c3e724fb1b73712d7701023d5",
            "2b1d2b135cfe4f7ca923c240e372787f",
            "6c785d48a481430e9a2fffe1024bf877",
            "b423a021e56d4d6bb14ad688911cd853",
            "c742dbb45aa94c958f54a8142827b7ab",
            "71182b64ab894befbc057d25e0cf9002",
            "7934a4de7d4b4704ab08951fdd513064",
            "6f19c7ddfd5748349a44c005cf4f5f28",
            "5ff9a371cfef455daa7adcaff12613fd",
            "d8c45a060233496386422a5ebe97e54c",
            "4b331da4a8b3412d9627176198d9c38c",
            "615262f92c97492ca51129a4e2be4df8",
            "91cd7de7a6bb439da816e9132cc220c9",
            "c5a68f1490e1445e8dec212e3b43032f",
            "d44151750a354496a66ca43307b1f3da",
            "20d6f0a0d1cc4e0981087a5e617dddcf",
            "091bfdf8d6b14589aa181623079fd7f4",
            "80529e82f6134d878efbc6fac96734af",
            "8a85162dfeae417db95ca0c2b1a42a07",
            "6e53d1bfd2be4cd9909875c26d9a46f0",
            "e5f3e4bc76ea4822920b1fd350fb6e8f",
            "916dbcf86aea4325a7035c33de900c75",
            "fb1e513926254c6a8ebc1a94d5f9b520",
            "262cdfe758954d2a93ee6fc7fc87306e",
            "d021194568b54ccda9254faae45f6dc6",
            "1b17af7869174e52bbd8e5717935a274",
            "6e8d471fc63d442d9fff4a0fc82bf7a0",
            "3b3144f85b164848ab28fa9bb594c82a",
            "78db3778d8014e7999bbd0c06be9b287",
            "8ec10fc63a9a4735952726d98d9d1351"
          ]
        },
        "id": "I116KPIMOqvU",
        "outputId": "2c5f514e-6021-433c-bd66-741a396fd92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4f8af11c74d4e269d8ec3bed6cfd7f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ff9a371cfef455daa7adcaff12613fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e53d1bfd2be4cd9909875c26d9a46f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32100"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Prepare for Training\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "# T5 Tokenizer\n",
        "tokenizer=T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "# Vocab Size\n",
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mchun5jlP7BW",
        "outputId": "5563a499-6a71-41bb-e670-2174327c52a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32112"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Add Special Tokens: Table Tags\n",
        "tokenizer.add_special_tokens({\n",
        "    'additional_special_tokens': [\n",
        "        '<page_title>',\n",
        "        '</page_title>',\n",
        "        '<section_title>',\n",
        "        '</section_title>',\n",
        "        '<table>',\n",
        "        '</table>',\n",
        "        '<cell>',\n",
        "        '</cell>',\n",
        "        '<col_header>',\n",
        "        '</col_header>',\n",
        "        '<row_header>',\n",
        "        '</row_header>'\n",
        "    ]\n",
        "})\n",
        "# When Training, Resize PLM's Embedding Layer\n",
        "# model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Vocab Size\n",
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf-NoD4eQ3QV",
        "outputId": "8bee836c-380c-4f9c-a0d1-dfbb78c88d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<page_title>', '▁Swimming', '▁at', '▁the', '▁2012', '▁Summer', '▁Olympics', '▁', '–', '▁Men', \"'\", 's', '▁100', '▁', 'metre', '▁back', 'stroke', '</page_title>', '<section_title>', '▁Final', '</section_title>', '<table>', '<cell>', '▁4', '<col_header>', '▁', 'Rank', '</col_header>', '</cell>', '<cell>', '▁Camill', 'e', '▁La', 'court', '<col_header>', '▁Name', '</col_header>', '</cell>', '<cell>', '▁53', '.', '08', '<col_header>', '▁Time', '</col_header>', '</cell>', '</table>']\n"
          ]
        }
      ],
      "source": [
        "# Tokenize Linearized Cells\n",
        "print(tokenizer.tokenize(cells_linearized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlpUM6frTjeo"
      },
      "source": [
        "### **2. LoRA Finetuning (t5-small)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nsu1CqVgTmBy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Google's Official Preprocess Codes\n",
        "# https://github.com/google-research/language/blob/master/language/totto/baseline_preprocessing/preprocess_utils.py\n",
        "# from preprocess_utils import get_highlighted_subtable, linearize_subtable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhH0WM1nTwWu",
        "outputId": "c8db745a-f450-45d3-e5f4-52bd22c83f5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Pre-Trained T5 Tokenizer\n",
        "tokenizer=T5Tokenizer.from_pretrained('t5-small')\n",
        "# Add Special Tokens: Table Tags\n",
        "tokenizer.add_special_tokens({\n",
        "    'additional_special_tokens': [\n",
        "        '<page_title>',\n",
        "        '</page_title>',\n",
        "        '<section_title>',\n",
        "        '</section_title>',\n",
        "        '<table>',\n",
        "        '</table>',\n",
        "        '<cell>',\n",
        "        '</cell>',\n",
        "        '<col_header>',\n",
        "        '</col_header>',\n",
        "        '<row_header>',\n",
        "        '</row_header>'\n",
        "    ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "266b8559b485452d9a9ecd9f9b033706",
            "0fdff8e229a74576a17211fd625fa071",
            "f380278d7a434934854e514279f23b85",
            "f99e19ae8f9547d3b6dba48724bb66f8",
            "512e758103d747ee8c15ac097e1382b5",
            "6d37b2d2af824c7fa4ce1111559355e8",
            "5a55e6ba36b749419de3511ca2528fb1",
            "51ab1875e53548658b58a851347fb908",
            "d842077d4ae4443b84f9c4a63619687d",
            "49f814c623574a3ab5996e2c07daad99",
            "e2b60bd7314348058c946479c67f0d8f",
            "483e33b1b2fb421288496161592efbb1",
            "cae5d396e8c740f58e16e347a8fc5459",
            "61055184aee84415a57b92cb5b448f9b",
            "7890eaff068f4d29844f5d323904e406",
            "ffdf3ffb586b4620acc158eabe7223d9",
            "103a1ce77ab3441aaa8624ff85f71ae6",
            "441408621ebb4677be974d854dd2b106",
            "7b77f001467c4e9baccabc8fe8704d32",
            "3d583ddff4fe4766b7102b470f9147ba",
            "46505d4ec36e4e03a74d175035c84445",
            "315101f431de4f42b902871ba0684b75",
            "a0a841fab6b24a0192e8c22113a109d0",
            "5f08ba1cd66b4a71ae0ae89984a8adb4",
            "800a679b37ac4fb0a24f50b442d6aa34",
            "fa2e51768aa743329bac0c34a9e0ede4",
            "cf1ce54d945f4327a8783e877023be83",
            "eca56ac6b5bf49589a8c4a78aae71cfa",
            "babbf4270a524618ad5221757a7a3303",
            "1fee43fe99dc4d47854d963a8a2f6a96",
            "60bcffba0cfd4ccb96a12712d81aff42",
            "bdbfd09f0fbf4003a93caeb8c1055254",
            "966af38e93e7418f8e146795bf78fa8e"
          ]
        },
        "id": "wriQ2rUOqXpI",
        "outputId": "5793b927-3a50-45f5-c261-393fc31f3fbb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "266b8559b485452d9a9ecd9f9b033706"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "483e33b1b2fb421288496161592efbb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0a841fab6b24a0192e8c22113a109d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32112, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Pre-Trained T5 Model\n",
        "model=T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "# Resize PLM's Embedding Layer\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_33mwWhYGXA",
        "outputId": "2c93d01e-b5bd-4791-fcaa-9c43fcce4381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5ForConditionalGeneration(\n",
            "  (shared): Embedding(32112, 512)\n",
            "  (encoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32112, 512)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 8)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-5): 5 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32112, 512)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 8)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-5): 5 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=32112, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Original T5-small model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOV9dFTNSQho",
        "outputId": "4cb6eec5-a01f-4e6c-8905-8a9191b124af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 60498432\n",
            "all model parameters: 60498432\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "# Original T5-small model\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAilRSN8Xb1G",
        "outputId": "3d279893-cdb6-444d-c9c7-335f67271074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 294912\n",
            "all model parameters: 60793344\n",
            "percentage of trainable model parameters: 0.49%\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    task_type=\"SEQ_2_SEQ_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.01,\n",
        ")\n",
        "\n",
        "# LoRA T5-small model\n",
        "model = get_peft_model(model, peft_config)\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec6u6Ar2i_1K",
        "outputId": "b813f79e-bc36-4c8c-ec78-0019a45f9518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForSeq2SeqLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): T5ForConditionalGeneration(\n",
            "      (shared): Embedding(32112, 512)\n",
            "      (encoder): T5Stack(\n",
            "        (embed_tokens): Embedding(32112, 512)\n",
            "        (block): ModuleList(\n",
            "          (0): T5Block(\n",
            "            (layer): ModuleList(\n",
            "              (0): T5LayerSelfAttention(\n",
            "                (SelfAttention): T5Attention(\n",
            "                  (q): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "                  (v): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "                  (relative_attention_bias): Embedding(32, 8)\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (1): T5LayerFF(\n",
            "                (DenseReluDense): T5DenseActDense(\n",
            "                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  (act): ReLU()\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (1-5): 5 x T5Block(\n",
            "            (layer): ModuleList(\n",
            "              (0): T5LayerSelfAttention(\n",
            "                (SelfAttention): T5Attention(\n",
            "                  (q): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "                  (v): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (1): T5LayerFF(\n",
            "                (DenseReluDense): T5DenseActDense(\n",
            "                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  (act): ReLU()\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (final_layer_norm): T5LayerNorm()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (decoder): T5Stack(\n",
            "        (embed_tokens): Embedding(32112, 512)\n",
            "        (block): ModuleList(\n",
            "          (0): T5Block(\n",
            "            (layer): ModuleList(\n",
            "              (0): T5LayerSelfAttention(\n",
            "                (SelfAttention): T5Attention(\n",
            "                  (q): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "                  (v): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "                  (relative_attention_bias): Embedding(32, 8)\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (1): T5LayerCrossAttention(\n",
            "                (EncDecAttention): T5Attention(\n",
            "                  (q): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "                  (v): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (2): T5LayerFF(\n",
            "                (DenseReluDense): T5DenseActDense(\n",
            "                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  (act): ReLU()\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (1-5): 5 x T5Block(\n",
            "            (layer): ModuleList(\n",
            "              (0): T5LayerSelfAttention(\n",
            "                (SelfAttention): T5Attention(\n",
            "                  (q): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "                  (v): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (1): T5LayerCrossAttention(\n",
            "                (EncDecAttention): T5Attention(\n",
            "                  (q): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "                  (v): lora.Linear(\n",
            "                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
            "                    (lora_dropout): ModuleDict(\n",
            "                      (default): Dropout(p=0.01, inplace=False)\n",
            "                    )\n",
            "                    (lora_A): ModuleDict(\n",
            "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
            "                    )\n",
            "                    (lora_B): ModuleDict(\n",
            "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
            "                    )\n",
            "                    (lora_embedding_A): ParameterDict()\n",
            "                    (lora_embedding_B): ParameterDict()\n",
            "                  )\n",
            "                  (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (2): T5LayerFF(\n",
            "                (DenseReluDense): T5DenseActDense(\n",
            "                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  (act): ReLU()\n",
            "                )\n",
            "                (layer_norm): T5LayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (final_layer_norm): T5LayerNorm()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (lm_head): Linear(in_features=512, out_features=32112, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# LoRA T5-small model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6EqBOjVipXk",
        "outputId": "0912cc61-1325-448c-9035-e90feb5e243f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.model.shared.weight False\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight False\n",
            "base_model.model.encoder.block.0.layer.0.layer_norm.weight False\n",
            "base_model.model.encoder.block.0.layer.1.DenseReluDense.wi.weight False\n",
            "base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight False\n",
            "base_model.model.encoder.block.0.layer.1.layer_norm.weight False\n",
            "base_model.model.encoder.block.1.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.encoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.encoder.block.1.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.encoder.block.1.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.encoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.encoder.block.1.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.encoder.block.1.layer.0.layer_norm.weight False\n",
            "base_model.model.encoder.block.1.layer.1.DenseReluDense.wi.weight False\n",
            "base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight False\n",
            "base_model.model.encoder.block.1.layer.1.layer_norm.weight False\n",
            "base_model.model.encoder.block.2.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.encoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.encoder.block.2.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.encoder.block.2.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.encoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.encoder.block.2.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.encoder.block.2.layer.0.layer_norm.weight False\n",
            "base_model.model.encoder.block.2.layer.1.DenseReluDense.wi.weight False\n",
            "base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight False\n",
            "base_model.model.encoder.block.2.layer.1.layer_norm.weight False\n",
            "base_model.model.encoder.block.3.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.encoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.encoder.block.3.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.encoder.block.3.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.encoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.encoder.block.3.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.encoder.block.3.layer.0.layer_norm.weight False\n",
            "base_model.model.encoder.block.3.layer.1.DenseReluDense.wi.weight False\n",
            "base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight False\n",
            "base_model.model.encoder.block.3.layer.1.layer_norm.weight False\n",
            "base_model.model.encoder.block.4.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.encoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.encoder.block.4.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.encoder.block.4.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.encoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.encoder.block.4.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.encoder.block.4.layer.0.layer_norm.weight False\n",
            "base_model.model.encoder.block.4.layer.1.DenseReluDense.wi.weight False\n",
            "base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight False\n",
            "base_model.model.encoder.block.4.layer.1.layer_norm.weight False\n",
            "base_model.model.encoder.block.5.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.encoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.encoder.block.5.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.encoder.block.5.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.encoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.encoder.block.5.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.encoder.block.5.layer.0.layer_norm.weight False\n",
            "base_model.model.encoder.block.5.layer.1.DenseReluDense.wi.weight False\n",
            "base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight False\n",
            "base_model.model.encoder.block.5.layer.1.layer_norm.weight False\n",
            "base_model.model.encoder.final_layer_norm.weight False\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight False\n",
            "base_model.model.decoder.block.0.layer.0.layer_norm.weight False\n",
            "base_model.model.decoder.block.0.layer.1.EncDecAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight False\n",
            "base_model.model.decoder.block.0.layer.1.EncDecAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.0.layer.1.EncDecAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight False\n",
            "base_model.model.decoder.block.0.layer.1.layer_norm.weight False\n",
            "base_model.model.decoder.block.0.layer.2.DenseReluDense.wi.weight False\n",
            "base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight False\n",
            "base_model.model.decoder.block.0.layer.2.layer_norm.weight False\n",
            "base_model.model.decoder.block.1.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.decoder.block.1.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.1.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.decoder.block.1.layer.0.layer_norm.weight False\n",
            "base_model.model.decoder.block.1.layer.1.EncDecAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight False\n",
            "base_model.model.decoder.block.1.layer.1.EncDecAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.1.layer.1.EncDecAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight False\n",
            "base_model.model.decoder.block.1.layer.1.layer_norm.weight False\n",
            "base_model.model.decoder.block.1.layer.2.DenseReluDense.wi.weight False\n",
            "base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight False\n",
            "base_model.model.decoder.block.1.layer.2.layer_norm.weight False\n",
            "base_model.model.decoder.block.2.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.decoder.block.2.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.2.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.decoder.block.2.layer.0.layer_norm.weight False\n",
            "base_model.model.decoder.block.2.layer.1.EncDecAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight False\n",
            "base_model.model.decoder.block.2.layer.1.EncDecAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.2.layer.1.EncDecAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight False\n",
            "base_model.model.decoder.block.2.layer.1.layer_norm.weight False\n",
            "base_model.model.decoder.block.2.layer.2.DenseReluDense.wi.weight False\n",
            "base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight False\n",
            "base_model.model.decoder.block.2.layer.2.layer_norm.weight False\n",
            "base_model.model.decoder.block.3.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.decoder.block.3.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.3.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.decoder.block.3.layer.0.layer_norm.weight False\n",
            "base_model.model.decoder.block.3.layer.1.EncDecAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight False\n",
            "base_model.model.decoder.block.3.layer.1.EncDecAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.3.layer.1.EncDecAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight False\n",
            "base_model.model.decoder.block.3.layer.1.layer_norm.weight False\n",
            "base_model.model.decoder.block.3.layer.2.DenseReluDense.wi.weight False\n",
            "base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight False\n",
            "base_model.model.decoder.block.3.layer.2.layer_norm.weight False\n",
            "base_model.model.decoder.block.4.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.decoder.block.4.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.4.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.decoder.block.4.layer.0.layer_norm.weight False\n",
            "base_model.model.decoder.block.4.layer.1.EncDecAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight False\n",
            "base_model.model.decoder.block.4.layer.1.EncDecAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.4.layer.1.EncDecAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight False\n",
            "base_model.model.decoder.block.4.layer.1.layer_norm.weight False\n",
            "base_model.model.decoder.block.4.layer.2.DenseReluDense.wi.weight False\n",
            "base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight False\n",
            "base_model.model.decoder.block.4.layer.2.layer_norm.weight False\n",
            "base_model.model.decoder.block.5.layer.0.SelfAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight False\n",
            "base_model.model.decoder.block.5.layer.0.SelfAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.5.layer.0.SelfAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight False\n",
            "base_model.model.decoder.block.5.layer.0.layer_norm.weight False\n",
            "base_model.model.decoder.block.5.layer.1.EncDecAttention.q.base_layer.weight False\n",
            "base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
            "base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
            "base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight False\n",
            "base_model.model.decoder.block.5.layer.1.EncDecAttention.v.base_layer.weight False\n",
            "base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_A.default.weight True\n",
            "base_model.model.decoder.block.5.layer.1.EncDecAttention.v.lora_B.default.weight True\n",
            "base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight False\n",
            "base_model.model.decoder.block.5.layer.1.layer_norm.weight False\n",
            "base_model.model.decoder.block.5.layer.2.DenseReluDense.wi.weight False\n",
            "base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight False\n",
            "base_model.model.decoder.block.5.layer.2.layer_norm.weight False\n",
            "base_model.model.decoder.final_layer_norm.weight False\n"
          ]
        }
      ],
      "source": [
        "# 모든 파라미터 requires_grad 확인\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtSsofydy_x0"
      },
      "source": [
        "#### **LoRA Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AH4J5prg2XNa"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToTToDataset(Dataset):\n",
        "    def __init__(self, path_data, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "        self.attention_mask = []\n",
        "\n",
        "        # Load Dataset\n",
        "        with open(path_data, 'r') as f:\n",
        "            dataset = f.read().splitlines()\n",
        "\n",
        "        for _data in dataset:\n",
        "            data = json.loads(_data)\n",
        "\n",
        "            # Preprocess\n",
        "            subtable = get_highlighted_subtable(table=data['table'], cell_indices=data['highlighted_cells'], with_heuristic_headers=True)\n",
        "            cells_linearized = linearize_subtable(subtable=subtable, table_page_title=data['table_page_title'], table_section_title=data['table_section_title'])\n",
        "\n",
        "            # Encode\n",
        "            encoded_dict = tokenizer.encode_plus(cells_linearized, max_length=512, truncation=True, padding=\"max_length\", return_attention_mask=True)\n",
        "            self.data.append(encoded_dict['input_ids'])\n",
        "            self.attention_mask.append(encoded_dict['attention_mask'])\n",
        "            self.label.append(tokenizer.encode(data['sentence_annotations'][0]['final_sentence'], max_length=512, truncation=True))\n",
        "\n",
        "        print(len(self.data), 'datas')\n",
        "        print(len(self.label), 'labels')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(self.data[idx], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
        "            'labels': torch.tensor(self.label[idx], dtype=torch.long)\n",
        "        }\n",
        "        return item\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5CZd3E5EIKf",
        "outputId": "355fc986-30fa-48d4-de23-91303b15dbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120761 datas\n",
            "120761 labels\n"
          ]
        }
      ],
      "source": [
        "dataset_train = ToTToDataset(path_data=\"/content/drive/MyDrive/ToTTo_data/totto_train_data.jsonl\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wLUPOi_5sYHS"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "output_dir=\"/content/drive/MyDrive/ToTTo_T5-small_LoRA/model/epoch10\"\n",
        "\n",
        "# Define training args\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\t  auto_find_batch_size=True,\n",
        "    learning_rate=1e-3, # higher learning rate\n",
        "    num_train_epochs=10,\n",
        "    logging_dir=f\"{output_dir}/logs\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=2000,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "# Data collator 인스턴스 생성\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "# Seq2SeqTrainer 인스턴스 생성\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset_train,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpsG7Q0SKnKU"
      },
      "source": [
        "##### **Error debugging (Trainer.train())**\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "ValueError                                Traceback (most recent call last)\n",
        "<ipython-input-29-b7e217745f1c> in <cell line: 2>()\n",
        "*       1 # train model\n",
        "* ----> 2 trainer.train()\n",
        "\n",
        "9 frames\n",
        "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py in pad(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose) \\\\\n",
        "*    3212         # The model's main input name, usually `input_ids`, has be passed for padding\n",
        "*    3213         if self.model_input_names[0] not in encoded_inputs:\n",
        "* -> 3214             raise ValueError(\n",
        "*    3215                 \"You should supply an encoding or a list of encodings to this method \"\n",
        "*    3216                 f\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\n",
        "\n",
        "ValueError: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y4YiH4AHHLe",
        "outputId": "6cdc368a-d06d-4a9c-b914-31d8d1b02097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 43])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 임시 DataLoader 생성\n",
        "temp_loader = DataLoader(trainer.train_dataset, batch_size=4, collate_fn=data_collator)\n",
        "\n",
        "# 배치 데이터 형식 확인\n",
        "for batch in temp_loader:\n",
        "    print(batch.keys())\n",
        "    print(batch['input_ids'].shape)\n",
        "    print(batch['attention_mask'].shape)\n",
        "    if 'labels' in batch:\n",
        "        print(batch['labels'].shape)\n",
        "    break  # 첫 번째 배치만 확인하고 반복 중지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJjCjoCkKXYG",
        "outputId": "184fb54b-e0bd-4495-d17d-c1018f0379b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch keys: dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n",
            "input_ids: shape torch.Size([8, 512])\n",
            "attention_mask: shape torch.Size([8, 512])\n",
            "labels: shape torch.Size([8, 62])\n",
            "decoder_input_ids: shape torch.Size([8, 62])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# DataLoader 생성 시 collate_fn에 data_collator 지정\n",
        "sample_loader = DataLoader(trainer.train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator)\n",
        "\n",
        "# DataLoader에서 하나의 배치를 가져와서 확인\n",
        "sample_batch = next(iter(sample_loader))\n",
        "\n",
        "# 배치 데이터 확인\n",
        "print(\"Batch keys:\", sample_batch.keys())\n",
        "for key, value in sample_batch.items():\n",
        "    print(f\"{key}: shape {value.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4LOqa9FKy9O"
      },
      "source": [
        "#### **Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pZj9_UG9sYJ4",
        "outputId": "ff47c0e1-b506-4ad8-abc0-3cab3315e185"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150960' max='150960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150960/150960 9:40:07, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.790500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.622100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.587500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.555000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.532100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.518300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.510300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>1.498300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>1.483900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>1.471200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>1.462900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>1.477300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26000</td>\n",
              "      <td>1.457600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28000</td>\n",
              "      <td>1.449500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>1.436500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32000</td>\n",
              "      <td>1.437700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34000</td>\n",
              "      <td>1.430700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36000</td>\n",
              "      <td>1.419900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38000</td>\n",
              "      <td>1.428600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>1.421200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>1.421600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44000</td>\n",
              "      <td>1.417700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46000</td>\n",
              "      <td>1.420500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48000</td>\n",
              "      <td>1.418600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>1.406300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52000</td>\n",
              "      <td>1.405800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54000</td>\n",
              "      <td>1.402400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56000</td>\n",
              "      <td>1.392900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58000</td>\n",
              "      <td>1.395500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60000</td>\n",
              "      <td>1.387300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62000</td>\n",
              "      <td>1.380600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64000</td>\n",
              "      <td>1.385600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66000</td>\n",
              "      <td>1.381700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68000</td>\n",
              "      <td>1.381200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70000</td>\n",
              "      <td>1.378400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72000</td>\n",
              "      <td>1.376800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74000</td>\n",
              "      <td>1.382200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76000</td>\n",
              "      <td>1.358400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78000</td>\n",
              "      <td>1.362700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80000</td>\n",
              "      <td>1.368500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82000</td>\n",
              "      <td>1.370800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84000</td>\n",
              "      <td>1.366800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86000</td>\n",
              "      <td>1.356000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88000</td>\n",
              "      <td>1.350400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90000</td>\n",
              "      <td>1.344100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92000</td>\n",
              "      <td>1.356700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94000</td>\n",
              "      <td>1.347100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96000</td>\n",
              "      <td>1.340300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98000</td>\n",
              "      <td>1.341900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100000</td>\n",
              "      <td>1.341800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102000</td>\n",
              "      <td>1.333700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104000</td>\n",
              "      <td>1.334700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106000</td>\n",
              "      <td>1.333800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108000</td>\n",
              "      <td>1.328100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110000</td>\n",
              "      <td>1.316600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112000</td>\n",
              "      <td>1.331200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114000</td>\n",
              "      <td>1.324400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116000</td>\n",
              "      <td>1.328200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118000</td>\n",
              "      <td>1.324100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120000</td>\n",
              "      <td>1.321900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122000</td>\n",
              "      <td>1.311500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124000</td>\n",
              "      <td>1.311300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126000</td>\n",
              "      <td>1.316100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128000</td>\n",
              "      <td>1.304500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130000</td>\n",
              "      <td>1.300700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132000</td>\n",
              "      <td>1.308700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134000</td>\n",
              "      <td>1.311300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136000</td>\n",
              "      <td>1.297900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138000</td>\n",
              "      <td>1.285300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140000</td>\n",
              "      <td>1.301500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142000</td>\n",
              "      <td>1.297300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144000</td>\n",
              "      <td>1.299500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146000</td>\n",
              "      <td>1.288400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148000</td>\n",
              "      <td>1.292200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150000</td>\n",
              "      <td>1.305700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150960, training_loss=1.3879326121416684, metrics={'train_runtime': 34809.3021, 'train_samples_per_second': 34.692, 'train_steps_per_second': 4.337, 'total_flos': 1.6453417090154496e+17, 'train_loss': 1.3879326121416684, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# train model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRrWgDzSz0V5",
        "outputId": "8fd9cce4-b835-4a98-fd1a-b7fbeb598d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:160: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 모델 저장\n",
        "trainer.save_model(output_dir)\n",
        "\n",
        "# 모델 구성 저장 (필요한 경우)\n",
        "model.config.save_pretrained(output_dir)\n",
        "\n",
        "# 모델의 state_dict 저장 (safetensor는 모델의 구조가 바뀌는 경우 불러오기가 까다로워서 그냥 pth도 저장)\n",
        "torch.save(model.state_dict(), f'/content/drive/MyDrive/ToTTo_T5-small_LoRA/model/epoch10/T5-small_LoRA_Fine-Tuning_lr{training_args.learning_rate}_epoch10.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VpsG7Q0SKnKU"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4f8af11c74d4e269d8ec3bed6cfd7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afd05d0d61a442948f3b253e09d37988",
              "IPY_MODEL_989f28293b734a8baa4453926577793b",
              "IPY_MODEL_de16466c3e724fb1b73712d7701023d5"
            ],
            "layout": "IPY_MODEL_2b1d2b135cfe4f7ca923c240e372787f"
          }
        },
        "afd05d0d61a442948f3b253e09d37988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c785d48a481430e9a2fffe1024bf877",
            "placeholder": "​",
            "style": "IPY_MODEL_b423a021e56d4d6bb14ad688911cd853",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "989f28293b734a8baa4453926577793b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c742dbb45aa94c958f54a8142827b7ab",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71182b64ab894befbc057d25e0cf9002",
            "value": 2324
          }
        },
        "de16466c3e724fb1b73712d7701023d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7934a4de7d4b4704ab08951fdd513064",
            "placeholder": "​",
            "style": "IPY_MODEL_6f19c7ddfd5748349a44c005cf4f5f28",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 34.0kB/s]"
          }
        },
        "2b1d2b135cfe4f7ca923c240e372787f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c785d48a481430e9a2fffe1024bf877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b423a021e56d4d6bb14ad688911cd853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c742dbb45aa94c958f54a8142827b7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71182b64ab894befbc057d25e0cf9002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7934a4de7d4b4704ab08951fdd513064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f19c7ddfd5748349a44c005cf4f5f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff9a371cfef455daa7adcaff12613fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8c45a060233496386422a5ebe97e54c",
              "IPY_MODEL_4b331da4a8b3412d9627176198d9c38c",
              "IPY_MODEL_615262f92c97492ca51129a4e2be4df8"
            ],
            "layout": "IPY_MODEL_91cd7de7a6bb439da816e9132cc220c9"
          }
        },
        "d8c45a060233496386422a5ebe97e54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5a68f1490e1445e8dec212e3b43032f",
            "placeholder": "​",
            "style": "IPY_MODEL_d44151750a354496a66ca43307b1f3da",
            "value": "spiece.model: 100%"
          }
        },
        "4b331da4a8b3412d9627176198d9c38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d6f0a0d1cc4e0981087a5e617dddcf",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_091bfdf8d6b14589aa181623079fd7f4",
            "value": 791656
          }
        },
        "615262f92c97492ca51129a4e2be4df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80529e82f6134d878efbc6fac96734af",
            "placeholder": "​",
            "style": "IPY_MODEL_8a85162dfeae417db95ca0c2b1a42a07",
            "value": " 792k/792k [00:00&lt;00:00, 810kB/s]"
          }
        },
        "91cd7de7a6bb439da816e9132cc220c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a68f1490e1445e8dec212e3b43032f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44151750a354496a66ca43307b1f3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20d6f0a0d1cc4e0981087a5e617dddcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "091bfdf8d6b14589aa181623079fd7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80529e82f6134d878efbc6fac96734af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a85162dfeae417db95ca0c2b1a42a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e53d1bfd2be4cd9909875c26d9a46f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5f3e4bc76ea4822920b1fd350fb6e8f",
              "IPY_MODEL_916dbcf86aea4325a7035c33de900c75",
              "IPY_MODEL_fb1e513926254c6a8ebc1a94d5f9b520"
            ],
            "layout": "IPY_MODEL_262cdfe758954d2a93ee6fc7fc87306e"
          }
        },
        "e5f3e4bc76ea4822920b1fd350fb6e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d021194568b54ccda9254faae45f6dc6",
            "placeholder": "​",
            "style": "IPY_MODEL_1b17af7869174e52bbd8e5717935a274",
            "value": "tokenizer.json: 100%"
          }
        },
        "916dbcf86aea4325a7035c33de900c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8d471fc63d442d9fff4a0fc82bf7a0",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b3144f85b164848ab28fa9bb594c82a",
            "value": 1389353
          }
        },
        "fb1e513926254c6a8ebc1a94d5f9b520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78db3778d8014e7999bbd0c06be9b287",
            "placeholder": "​",
            "style": "IPY_MODEL_8ec10fc63a9a4735952726d98d9d1351",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "262cdfe758954d2a93ee6fc7fc87306e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d021194568b54ccda9254faae45f6dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b17af7869174e52bbd8e5717935a274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e8d471fc63d442d9fff4a0fc82bf7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b3144f85b164848ab28fa9bb594c82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78db3778d8014e7999bbd0c06be9b287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec10fc63a9a4735952726d98d9d1351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "266b8559b485452d9a9ecd9f9b033706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fdff8e229a74576a17211fd625fa071",
              "IPY_MODEL_f380278d7a434934854e514279f23b85",
              "IPY_MODEL_f99e19ae8f9547d3b6dba48724bb66f8"
            ],
            "layout": "IPY_MODEL_512e758103d747ee8c15ac097e1382b5"
          }
        },
        "0fdff8e229a74576a17211fd625fa071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d37b2d2af824c7fa4ce1111559355e8",
            "placeholder": "​",
            "style": "IPY_MODEL_5a55e6ba36b749419de3511ca2528fb1",
            "value": "config.json: 100%"
          }
        },
        "f380278d7a434934854e514279f23b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51ab1875e53548658b58a851347fb908",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d842077d4ae4443b84f9c4a63619687d",
            "value": 1206
          }
        },
        "f99e19ae8f9547d3b6dba48724bb66f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49f814c623574a3ab5996e2c07daad99",
            "placeholder": "​",
            "style": "IPY_MODEL_e2b60bd7314348058c946479c67f0d8f",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 17.3kB/s]"
          }
        },
        "512e758103d747ee8c15ac097e1382b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d37b2d2af824c7fa4ce1111559355e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a55e6ba36b749419de3511ca2528fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51ab1875e53548658b58a851347fb908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d842077d4ae4443b84f9c4a63619687d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49f814c623574a3ab5996e2c07daad99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b60bd7314348058c946479c67f0d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "483e33b1b2fb421288496161592efbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cae5d396e8c740f58e16e347a8fc5459",
              "IPY_MODEL_61055184aee84415a57b92cb5b448f9b",
              "IPY_MODEL_7890eaff068f4d29844f5d323904e406"
            ],
            "layout": "IPY_MODEL_ffdf3ffb586b4620acc158eabe7223d9"
          }
        },
        "cae5d396e8c740f58e16e347a8fc5459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_103a1ce77ab3441aaa8624ff85f71ae6",
            "placeholder": "​",
            "style": "IPY_MODEL_441408621ebb4677be974d854dd2b106",
            "value": "model.safetensors: 100%"
          }
        },
        "61055184aee84415a57b92cb5b448f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b77f001467c4e9baccabc8fe8704d32",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d583ddff4fe4766b7102b470f9147ba",
            "value": 242043056
          }
        },
        "7890eaff068f4d29844f5d323904e406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46505d4ec36e4e03a74d175035c84445",
            "placeholder": "​",
            "style": "IPY_MODEL_315101f431de4f42b902871ba0684b75",
            "value": " 242M/242M [00:01&lt;00:00, 186MB/s]"
          }
        },
        "ffdf3ffb586b4620acc158eabe7223d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "103a1ce77ab3441aaa8624ff85f71ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "441408621ebb4677be974d854dd2b106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b77f001467c4e9baccabc8fe8704d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d583ddff4fe4766b7102b470f9147ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46505d4ec36e4e03a74d175035c84445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315101f431de4f42b902871ba0684b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0a841fab6b24a0192e8c22113a109d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f08ba1cd66b4a71ae0ae89984a8adb4",
              "IPY_MODEL_800a679b37ac4fb0a24f50b442d6aa34",
              "IPY_MODEL_fa2e51768aa743329bac0c34a9e0ede4"
            ],
            "layout": "IPY_MODEL_cf1ce54d945f4327a8783e877023be83"
          }
        },
        "5f08ba1cd66b4a71ae0ae89984a8adb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca56ac6b5bf49589a8c4a78aae71cfa",
            "placeholder": "​",
            "style": "IPY_MODEL_babbf4270a524618ad5221757a7a3303",
            "value": "generation_config.json: 100%"
          }
        },
        "800a679b37ac4fb0a24f50b442d6aa34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fee43fe99dc4d47854d963a8a2f6a96",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60bcffba0cfd4ccb96a12712d81aff42",
            "value": 147
          }
        },
        "fa2e51768aa743329bac0c34a9e0ede4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdbfd09f0fbf4003a93caeb8c1055254",
            "placeholder": "​",
            "style": "IPY_MODEL_966af38e93e7418f8e146795bf78fa8e",
            "value": " 147/147 [00:00&lt;00:00, 2.59kB/s]"
          }
        },
        "cf1ce54d945f4327a8783e877023be83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca56ac6b5bf49589a8c4a78aae71cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "babbf4270a524618ad5221757a7a3303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fee43fe99dc4d47854d963a8a2f6a96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60bcffba0cfd4ccb96a12712d81aff42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdbfd09f0fbf4003a93caeb8c1055254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966af38e93e7418f8e146795bf78fa8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}