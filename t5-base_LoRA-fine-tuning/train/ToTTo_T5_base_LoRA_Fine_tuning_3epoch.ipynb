{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRiIL3GkTTA0"
      },
      "source": [
        "## **T5-base LoRA Fine-tuning on ToTTo**\n",
        "\n",
        "From : [JooYoung Song](https://github.com/Song-Joo-Young/ToTTo-Fine-tuning-in-colab/tree/main)\n",
        "\n",
        "Code Reference :\n",
        "* PEFT : https://huggingface.co/docs/peft/main/en/index\n",
        "* ToTTo : https://github.com/google-research-datasets/ToTTo\n",
        "* Prompt-Tuning-on-ToTTo : https://github.com/ChainsmokersAI/Prompt-Tuning-on-ToTTo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgHe6df5gl9I",
        "outputId": "b1031eb1-1b86-4f77-b459-cddb937da26a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Drive Mount\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsYkg24SX36S",
        "outputId": "98c8422f-69b6-4f01-cfd6-7112955ab886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-10 00:08:44--  https://storage.googleapis.com/totto-public/totto_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.207, 173.194.202.207, 173.194.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 187724372 (179M) [application/zip]\n",
            "Saving to: ‘totto_data.zip’\n",
            "\n",
            "totto_data.zip      100%[===================>] 179.03M  82.3MB/s    in 2.2s    \n",
            "\n",
            "2024-02-10 00:08:46 (82.3 MB/s) - ‘totto_data.zip’ saved [187724372/187724372]\n",
            "\n",
            "Archive:  totto_data.zip\n",
            "  inflating: totto_data/totto_dev_data.jsonl  \n",
            "  inflating: totto_data/totto_train_data.jsonl  \n",
            "  inflating: totto_data/unlabeled_totto_test_data.jsonl  \n"
          ]
        }
      ],
      "source": [
        "# Get Dataset\n",
        "\n",
        "!wget https://storage.googleapis.com/totto-public/totto_data.zip\n",
        "!unzip totto_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HSDPyw28Xclb",
        "outputId": "1c3fdc39-e989-4de9-bfd2-124ad9285eec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ToTTo_data'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 드라이브에 데이터셋 저장 추후 가중치도 저장할 폴더\n",
        "# Copy Dataset to your Google Drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "source_folder = '/content/totto_data'\n",
        "destination_folder = '/content/drive/MyDrive/ToTTo_data'\n",
        "\n",
        "if os.path.exists(destination_folder):\n",
        "    shutil.rmtree(destination_folder)\n",
        "\n",
        "shutil.copytree(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SifiwLhvTfAL"
      },
      "source": [
        "### **1. Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJOHz_ZYCiOV",
        "outputId": "41d821b8-4b5e-4844-8dfc-a2b62168c53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting peft\n",
            "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.27.0-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/279.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: pyarrow, dill, responses, multiprocess, accelerate, datasets, peft, evaluate\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.27.0 datasets-2.17.0 dill-0.3.8 evaluate-0.4.1 multiprocess-0.70.16 peft-0.8.2 pyarrow-15.0.0 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets sentencepiece peft accelerate evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73SN1-ioXipz",
        "outputId": "27cd05fb-2d92-4d34-f4c6-bccb8fe55b94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120761"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Load Train Set\n",
        "# with open('/content/totto_data/totto_train_data.jsonl', 'r') as f:\n",
        "with open('/content/drive/MyDrive/ToTTo_data/totto_train_data.jsonl', 'r') as f:\n",
        "    data_train=f.read().splitlines()\n",
        "    f.close()\n",
        "\n",
        "# Number of Train Data\n",
        "len(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3iIU_s2CliG",
        "outputId": "2eb5c464-03fc-4b89-dab0-03d352fc04bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ table \n",
            " \t  [[{'value': 'Rank', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Lane', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Name', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Nationality', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Time', 'is_header': True, 'column_span': 1, 'row_span': 1}, {'value': 'Notes', 'is_header': True, 'column_span': 1, 'row_span': 1}], [{'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '4', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Matt Grevers', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'United States', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '52.16', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'OR', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '2', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Nick Thoman', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'United States', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '52.92', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '6', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Ryosuke Irie', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Japan', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '52.97', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '4', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '5', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Camille Lacourt', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'France', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.08', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '5', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '3', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Liam Tancock', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Great Britain', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.35', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '6', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '1', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Helge Meeuw', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Germany', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.48', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '7', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '8', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Hayden Stoeckel', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Australia', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.55', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}], [{'value': '8', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '7', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'Cheng Feiyi', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': 'China', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '53.77', 'is_header': False, 'column_span': 1, 'row_span': 1}, {'value': '', 'is_header': False, 'column_span': 1, 'row_span': 1}]]\n",
            "→ table_webpage_url \n",
            " \t  http://en.wikipedia.org/wiki/Swimming_at_the_2012_Summer_Olympics_%E2%80%93_Men's_100_metre_backstroke\n",
            "→ table_page_title \n",
            " \t  Swimming at the 2012 Summer Olympics – Men's 100 metre backstroke\n",
            "→ table_section_title \n",
            " \t  Final\n",
            "→ table_section_text \n",
            " \t  \n",
            "→ highlighted_cells \n",
            " \t  [[4, 0], [4, 2], [4, 4]]\n",
            "→ example_id \n",
            " \t  -2235792344822110317\n",
            "→ sentence_annotations \n",
            " \t  [{'original_sentence': 'Leading the race early on the initial length, Lacourt dropped off the podium to a fourth-place time in 53.08.', 'sentence_after_deletion': 'Lacourt dropped to a fourth-place time in 53.08.', 'sentence_after_ambiguity': 'Lacourt was dropped to a fourth-place time in 53.08.', 'final_sentence': 'Lacourt was dropped to a fourth-place time in 53.08.'}]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Sample Data\n",
        "data_sample=json.loads(data_train[-1])\n",
        "\n",
        "# Key-Value Set\n",
        "for key, value in data_sample.items():\n",
        "    # if key=='table': continue\n",
        "\n",
        "    print('→', key, '\\n \\t ', value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHA8DvraYjJs"
      },
      "outputs": [],
      "source": [
        "# Google's Official Preprocess Codes\n",
        "# https://github.com/google-research/language/blob/master/language/totto/baseline_preprocessing/preprocess_utils.py\n",
        "\n",
        "import copy\n",
        "\n",
        "def _add_adjusted_col_offsets(table):\n",
        "  \"\"\"Add adjusted column offsets to take into account multi-column cells.\"\"\"\n",
        "  adjusted_table = []\n",
        "  for row in table:\n",
        "    real_col_index = 0\n",
        "    adjusted_row = []\n",
        "    for cell in row:\n",
        "      adjusted_cell = copy.deepcopy(cell)\n",
        "      adjusted_cell[\"adjusted_col_start\"] = real_col_index\n",
        "      adjusted_cell[\"adjusted_col_end\"] = (\n",
        "          adjusted_cell[\"adjusted_col_start\"] + adjusted_cell[\"column_span\"])\n",
        "      real_col_index += adjusted_cell[\"column_span\"]\n",
        "      adjusted_row.append(adjusted_cell)\n",
        "    adjusted_table.append(adjusted_row)\n",
        "  return adjusted_table\n",
        "\n",
        "\n",
        "def _get_heuristic_row_headers(adjusted_table, row_index, col_index):\n",
        "  \"\"\"Heuristic to find row headers.\"\"\"\n",
        "  row_headers = []\n",
        "  row = adjusted_table[row_index]\n",
        "  for i in range(0, col_index):\n",
        "    if row[i][\"is_header\"]:\n",
        "      row_headers.append(row[i])\n",
        "  return row_headers\n",
        "\n",
        "\n",
        "def _get_heuristic_col_headers(adjusted_table, row_index, col_index):\n",
        "  \"\"\"Heuristic to find column headers.\"\"\"\n",
        "  adjusted_cell = adjusted_table[row_index][col_index]\n",
        "  adjusted_col_start = adjusted_cell[\"adjusted_col_start\"]\n",
        "  adjusted_col_end = adjusted_cell[\"adjusted_col_end\"]\n",
        "  col_headers = []\n",
        "  for r in range(0, row_index):\n",
        "    row = adjusted_table[r]\n",
        "    for cell in row:\n",
        "      if (cell[\"adjusted_col_start\"] < adjusted_col_end and\n",
        "          cell[\"adjusted_col_end\"] > adjusted_col_start):\n",
        "        if cell[\"is_header\"]:\n",
        "          col_headers.append(cell)\n",
        "\n",
        "  return col_headers\n",
        "\n",
        "\n",
        "def get_highlighted_subtable(table, cell_indices, with_heuristic_headers=False):\n",
        "  \"\"\"Extract out the highlighted part of a table.\"\"\"\n",
        "  highlighted_table = []\n",
        "\n",
        "  adjusted_table = _add_adjusted_col_offsets(table)\n",
        "\n",
        "  for (row_index, col_index) in cell_indices:\n",
        "    cell = table[row_index][col_index]\n",
        "    if with_heuristic_headers:\n",
        "      row_headers = _get_heuristic_row_headers(adjusted_table, row_index,\n",
        "                                               col_index)\n",
        "      col_headers = _get_heuristic_col_headers(adjusted_table, row_index,\n",
        "                                               col_index)\n",
        "    else:\n",
        "      row_headers = []\n",
        "      col_headers = []\n",
        "\n",
        "    highlighted_cell = {\n",
        "        \"cell\": cell,\n",
        "        \"row_headers\": row_headers,\n",
        "        \"col_headers\": col_headers\n",
        "    }\n",
        "    highlighted_table.append(highlighted_cell)\n",
        "\n",
        "  return highlighted_table\n",
        "\n",
        "\n",
        "def linearize_full_table(table, cell_indices, table_page_title,\n",
        "                         table_section_title):\n",
        "  \"\"\"Linearize full table with localized headers and return a string.\"\"\"\n",
        "  table_str = \"\"\n",
        "  if table_page_title:\n",
        "    table_str += \"<page_title> \" + table_page_title + \" </page_title> \"\n",
        "  if table_section_title:\n",
        "    table_str += \"<section_title> \" + table_section_title + \" </section_title> \"\n",
        "\n",
        "  table_str += \"<table> \"\n",
        "  adjusted_table = _add_adjusted_col_offsets(table)\n",
        "  for r_index, row in enumerate(table):\n",
        "    row_str = \"<row> \"\n",
        "    for c_index, col in enumerate(row):\n",
        "\n",
        "      row_headers = _get_heuristic_row_headers(adjusted_table, r_index, c_index)\n",
        "      col_headers = _get_heuristic_col_headers(adjusted_table, r_index, c_index)\n",
        "\n",
        "      # Distinguish between highlighted and non-highlighted cells.\n",
        "      if [r_index, c_index] in cell_indices:\n",
        "        start_cell_marker = \"<highlighted_cell> \"\n",
        "        end_cell_marker = \"</highlighted_cell> \"\n",
        "      else:\n",
        "        start_cell_marker = \"<cell> \"\n",
        "        end_cell_marker = \"</cell> \"\n",
        "\n",
        "      # The value of the cell.\n",
        "      item_str = start_cell_marker + col[\"value\"] + \" \"\n",
        "\n",
        "      # All the column headers associated with this cell.\n",
        "      for col_header in col_headers:\n",
        "        item_str += \"<col_header> \" + col_header[\"value\"] + \" </col_header> \"\n",
        "\n",
        "      # All the row headers associated with this cell.\n",
        "      for row_header in row_headers:\n",
        "        item_str += \"<row_header> \" + row_header[\"value\"] + \" </row_header> \"\n",
        "\n",
        "      item_str += end_cell_marker\n",
        "      row_str += item_str\n",
        "\n",
        "    row_str += \"</row> \"\n",
        "    table_str += row_str\n",
        "\n",
        "  table_str += \"</table>\"\n",
        "  if cell_indices:\n",
        "    assert \"<highlighted_cell>\" in table_str\n",
        "  return table_str\n",
        "\n",
        "\n",
        "def linearize_subtable(subtable, table_page_title, table_section_title):\n",
        "  \"\"\"Linearize the highlighted subtable and return a string of its contents.\"\"\"\n",
        "  table_str = \"\"\n",
        "  if table_page_title:\n",
        "    table_str += \"<page_title> \" + table_page_title + \" </page_title> \"\n",
        "  if table_section_title:\n",
        "    table_str += \"<section_title> \" + table_section_title + \" </section_title> \"\n",
        "  table_str += \"<table> \"\n",
        "\n",
        "  for item in subtable:\n",
        "    cell = item[\"cell\"]\n",
        "    row_headers = item[\"row_headers\"]\n",
        "    col_headers = item[\"col_headers\"]\n",
        "\n",
        "    # The value of the cell.\n",
        "    item_str = \"<cell> \" + cell[\"value\"] + \" \"\n",
        "\n",
        "    # All the column headers associated with this cell.\n",
        "    for col_header in col_headers:\n",
        "      item_str += \"<col_header> \" + col_header[\"value\"] + \" </col_header> \"\n",
        "\n",
        "    # All the row headers associated with this cell.\n",
        "    for row_header in row_headers:\n",
        "      item_str += \"<row_header> \" + row_header[\"value\"] + \" </row_header> \"\n",
        "\n",
        "    item_str += \"</cell> \"\n",
        "    table_str += item_str\n",
        "\n",
        "  table_str += \"</table>\"\n",
        "  return table_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkf__eetM00D",
        "outputId": "132e0931-bd9f-4aea-8e1e-f2875341f382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Highlighted Cells\n",
            "{'value': '4', 'is_header': False, 'column_span': 1, 'row_span': 1}\n",
            "{'value': 'Camille Lacourt', 'is_header': False, 'column_span': 1, 'row_span': 1}\n",
            "{'value': '53.08', 'is_header': False, 'column_span': 1, 'row_span': 1}\n",
            "\n",
            "→ Linearized (Preprocessed) Cells\n",
            "<page_title> Swimming at the 2012 Summer Olympics – Men's 100 metre backstroke </page_title> <section_title> Final </section_title> <table> <cell> 4 <col_header> Rank </col_header> </cell> <cell> Camille Lacourt <col_header> Name </col_header> </cell> <cell> 53.08 <col_header> Time </col_header> </cell> </table>\n",
            "\n",
            "→ Final (Label) Sentence\n",
            "Lacourt was dropped to a fourth-place time in 53.08.\n"
          ]
        }
      ],
      "source": [
        "# from preprocess_utils import get_highlighted_subtable, linearize_subtable\n",
        "\n",
        "print('→', 'Highlighted Cells')\n",
        "for (index_row, index_col) in data_sample['highlighted_cells']:\n",
        "    print(data_sample['table'][index_row][index_col])\n",
        "\n",
        "print('\\n→', 'Linearized (Preprocessed) Cells')\n",
        "subtable=get_highlighted_subtable(table=data_sample['table'], cell_indices=data_sample['highlighted_cells'], with_heuristic_headers=True)\n",
        "cells_linearized=linearize_subtable(\n",
        "    subtable=subtable,\n",
        "    table_page_title=data_sample['table_page_title'],\n",
        "    table_section_title=data_sample['table_section_title']\n",
        ")\n",
        "print(cells_linearized)\n",
        "\n",
        "print('\\n→', 'Final (Label) Sentence')\n",
        "for sentence in data_sample['sentence_annotations']:\n",
        "    print(sentence['final_sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for Training\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "# T5 Tokenizer\n",
        "tokenizer=T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "# Vocab Size\n",
        "len(tokenizer)"
      ],
      "metadata": {
        "id": "BUjchz60ChCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mchun5jlP7BW"
      },
      "outputs": [],
      "source": [
        "# Add Special Tokens: Table Tags\n",
        "tokenizer.add_special_tokens({\n",
        "    'additional_special_tokens': [\n",
        "        '<page_title>',\n",
        "        '</page_title>',\n",
        "        '<section_title>',\n",
        "        '</section_title>',\n",
        "        '<table>',\n",
        "        '</table>',\n",
        "        '<cell>',\n",
        "        '</cell>',\n",
        "        '<col_header>',\n",
        "        '</col_header>',\n",
        "        '<row_header>',\n",
        "        '</row_header>'\n",
        "    ]\n",
        "})\n",
        "# When Training, Resize PLM's Embedding Layer\n",
        "# model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Vocab Size\n",
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf-NoD4eQ3QV"
      },
      "outputs": [],
      "source": [
        "# Tokenize Linearized Cells\n",
        "print(tokenizer.tokenize(cells_linearized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlpUM6frTjeo"
      },
      "source": [
        "### **2. LoRA Finetuning (t5-small)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nsu1CqVgTmBy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Google's Official Preprocess Codes\n",
        "# https://github.com/google-research/language/blob/master/language/totto/baseline_preprocessing/preprocess_utils.py\n",
        "# from preprocess_utils import get_highlighted_subtable, linearize_subtable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhH0WM1nTwWu"
      },
      "outputs": [],
      "source": [
        "# Pre-Trained T5 Tokenizer\n",
        "tokenizer=T5Tokenizer.from_pretrained('t5-base')\n",
        "# Add Special Tokens: Table Tags\n",
        "tokenizer.add_special_tokens({\n",
        "    'additional_special_tokens': [\n",
        "        '<page_title>',\n",
        "        '</page_title>',\n",
        "        '<section_title>',\n",
        "        '</section_title>',\n",
        "        '<table>',\n",
        "        '</table>',\n",
        "        '<cell>',\n",
        "        '</cell>',\n",
        "        '<col_header>',\n",
        "        '</col_header>',\n",
        "        '<row_header>',\n",
        "        '</row_header>'\n",
        "    ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wriQ2rUOqXpI"
      },
      "outputs": [],
      "source": [
        "# Pre-Trained T5 Model\n",
        "model=T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "# Resize PLM's Embedding Layer\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_33mwWhYGXA"
      },
      "outputs": [],
      "source": [
        "# Original T5-base model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOV9dFTNSQho"
      },
      "outputs": [],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "# Original T5-base model\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAilRSN8Xb1G"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    task_type=\"SEQ_2_SEQ_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.01,\n",
        ")\n",
        "\n",
        "# LoRA T5-base model\n",
        "model = get_peft_model(model, peft_config)\n",
        "print(print_number_of_trainable_model_parameters(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec6u6Ar2i_1K"
      },
      "outputs": [],
      "source": [
        "# LoRA T5-base model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6EqBOjVipXk"
      },
      "outputs": [],
      "source": [
        "# 모든 파라미터 requires_grad 확인\n",
        "for name, param in model.named_parameters():\n",
        "    print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtSsofydy_x0"
      },
      "source": [
        "#### **LoRA Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH4J5prg2XNa"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToTToDataset(Dataset):\n",
        "    def __init__(self, path_data, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "        self.attention_mask = []\n",
        "\n",
        "        # Load Dataset\n",
        "        with open(path_data, 'r') as f:\n",
        "            dataset = f.read().splitlines()\n",
        "\n",
        "        for _data in dataset:\n",
        "            data = json.loads(_data)\n",
        "\n",
        "            # Preprocess\n",
        "            subtable = get_highlighted_subtable(table=data['table'], cell_indices=data['highlighted_cells'], with_heuristic_headers=True)\n",
        "            cells_linearized = linearize_subtable(subtable=subtable, table_page_title=data['table_page_title'], table_section_title=data['table_section_title'])\n",
        "\n",
        "            # Encode\n",
        "            encoded_dict = tokenizer.encode_plus(cells_linearized, max_length=512, truncation=True, padding=\"max_length\", return_attention_mask=True)\n",
        "            self.data.append(encoded_dict['input_ids'])\n",
        "            self.attention_mask.append(encoded_dict['attention_mask'])\n",
        "            self.label.append(tokenizer.encode(data['sentence_annotations'][0]['final_sentence'], max_length=512, truncation=True))\n",
        "\n",
        "        print(len(self.data), 'datas')\n",
        "        print(len(self.label), 'labels')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(self.data[idx], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
        "            'labels': torch.tensor(self.label[idx], dtype=torch.long)\n",
        "        }\n",
        "        return item\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5CZd3E5EIKf"
      },
      "outputs": [],
      "source": [
        "dataset_train = ToTToDataset(path_data=\"/content/drive/MyDrive/ToTTo_data/totto_train_data.jsonl\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLUPOi_5sYHS"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "# output_dir=\"/content/drive/MyDrive/ToTTo_T5-base_LoRA/model/epoch1\"\n",
        "output_dir = \"/content/drive/MyDrive/ToTTo_T5-base_LoRA/model/epoch4\"\n",
        "\n",
        "# Define training args\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\t  auto_find_batch_size=True,\n",
        "    learning_rate=1e-3, # higher learning rate\n",
        "    num_train_epochs=1,\n",
        "    logging_dir=f\"{output_dir}/logs\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=2000,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "# Data collator 인스턴스 생성\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "# Seq2SeqTrainer 인스턴스 생성\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset_train,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4LOqa9FKy9O"
      },
      "source": [
        "#### **Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "pZj9_UG9sYJ4",
        "outputId": "57dec560-2f30-44e8-a677-2bd23da20a09"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15096' max='15096' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15096/15096 3:25:06, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.392900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.259300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.219700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.185100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.155500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.133100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.115500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:160: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "trainer.train()\n",
        "\n",
        "# 모델 저장\n",
        "trainer.save_model(output_dir)\n",
        "\n",
        "# 모델 구성 저장 (필요한 경우)\n",
        "model.config.save_pretrained(output_dir)\n",
        "\n",
        "# 모델의 state_dict 저장 (safetensor는 모델의 구조가 바뀌는 경우 불러오기가 까다로워서 그냥 pth도 저장)\n",
        "torch.save(model.state_dict(), f'{output_dir}/T5-base_LoRA_Fine-Tuning_lr{training_args.learning_rate}_epoch1.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "wRrWgDzSz0V5",
        "outputId": "f8a6116e-038e-4669-aecf-74da38ca09f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15096' max='15096' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15096/15096 3:24:56, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.181700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.172800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.149400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.143900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.128500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.087500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.069000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "output_dir=\"/content/drive/MyDrive/ToTTo_T5-base_LoRA/model/epoch2\"\n",
        "\n",
        "# train model\n",
        "trainer.train()\n",
        "\n",
        "# 모델 저장\n",
        "trainer.save_model(output_dir)\n",
        "\n",
        "# 모델 구성 저장 (필요한 경우)\n",
        "model.config.save_pretrained(output_dir)\n",
        "\n",
        "# 모델의 state_dict 저장 (safetensor는 모델의 구조가 바뀌는 경우 불러오기가 까다로워서 그냥 pth도 저장)\n",
        "torch.save(model.state_dict(), f'{output_dir}/T5-base_LoRA_Fine-Tuning_lr{training_args.learning_rate}_epoch2.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Runtime Reset**"
      ],
      "metadata": {
        "id": "ZOKAr74JW49U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current GPU Index:\", torch.cuda.current_device())\n",
        "    print(\"Current GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
      ],
      "metadata": {
        "id": "SPjw_1mUPTZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0de927-9d9d-401a-b6e2-e412aa269b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU Index: 0\n",
            "Current GPU Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='/content/drive/MyDrive/ToTTo_T5-base_LoRA/model/epoch2/T5-base_LoRA_Fine-Tuning_lr0.001_epoch2.pth'\n",
        "\n",
        "# 저장된 state_dict 로드\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "I5WBqyAnWTgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a77ca87-de82-48e0-c83b-e77342fdac8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32112, 768)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32112, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32112, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=32112, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "\n",
        "output_dir=\"/content/drive/MyDrive/ToTTo_T5-base_LoRA/model/epoch3\"\n",
        "\n",
        "# Define training args\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\t  auto_find_batch_size=True,\n",
        "    learning_rate=1e-3, # higher learning rate\n",
        "    num_train_epochs=1,\n",
        "    logging_dir=f\"{output_dir}/logs\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=2000,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "# Data collator 인스턴스 생성\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "# Seq2SeqTrainer 인스턴스 생성\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset_train,\n",
        ")\n",
        "\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "MFklEvAPPlt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "trainer.train()\n",
        "\n",
        "# 모델 저장\n",
        "trainer.save_model(output_dir)\n",
        "\n",
        "# 모델 구성 저장 (필요한 경우)\n",
        "model.config.save_pretrained(output_dir)\n",
        "\n",
        "# 모델의 state_dict 저장 (safetensor는 모델의 구조가 바뀌는 경우 불러오기가 까다로워서 그냥 pth도 저장)\n",
        "torch.save(model.state_dict(), f'{output_dir}/T5-base_LoRA_Fine-Tuning_lr{training_args.learning_rate}_epoch3.pth')"
      ],
      "metadata": {
        "id": "-2P2aNwoY6ag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "dac60f93-bf8e-4c73-ddd5-58468f68556d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15096' max='15096' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15096/15096 3:19:45, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.131000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.130300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.122200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.101900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.084300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>1.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>1.062300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:160: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}