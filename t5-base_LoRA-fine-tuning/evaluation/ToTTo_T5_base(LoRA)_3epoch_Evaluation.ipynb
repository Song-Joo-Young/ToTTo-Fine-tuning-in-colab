{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3-_2u4C5AlQ"
      },
      "source": [
        "# **T5-base LoRA fine-tuning Evaluate**\n",
        "\n",
        "From : [JooYoung Song](https://github.com/Song-Joo-Young/ToTTo-Fine-tuning-in-colab/tree/main)\n",
        "\n",
        "Code Reference :\n",
        "* ToTTo : https://github.com/google-research-datasets/ToTTo\n",
        "* BLEURT : https://github.com/google-research/bleurt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcKQtoUc5EZ0"
      },
      "source": [
        "## **1.1 Google Drive mound & install library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub_MeipY5C34",
        "outputId": "452ee0f4-1a59-4921-e078-f6f481f13b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVI2kV9c5gla",
        "outputId": "2a9d5219-0a6a-4945-9fdf-b1cec63b15b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting peft\n",
            "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.27.0-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/279.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: pyarrow, dill, responses, multiprocess, accelerate, datasets, peft, evaluate\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.27.0 datasets-2.17.0 dill-0.3.8 evaluate-0.4.1 multiprocess-0.70.16 peft-0.8.2 pyarrow-15.0.0 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets sentencepiece peft accelerate evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dvw15nrV5k_s"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "# from preprocess_utils import get_highlighted_subtable, linearize_subtable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTMoye2bJyWb"
      },
      "source": [
        "## **1.2 Preprocessing code (ToTTo dataset)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xu7EJRNf5nAr"
      },
      "outputs": [],
      "source": [
        "# Google's Official Preprocess Codes\n",
        "# https://github.com/google-research/language/blob/master/language/totto/baseline_preprocessing/preprocess_utils.py\n",
        "\n",
        "import copy\n",
        "\n",
        "def _add_adjusted_col_offsets(table):\n",
        "  \"\"\"Add adjusted column offsets to take into account multi-column cells.\"\"\"\n",
        "  adjusted_table = []\n",
        "  for row in table:\n",
        "    real_col_index = 0\n",
        "    adjusted_row = []\n",
        "    for cell in row:\n",
        "      adjusted_cell = copy.deepcopy(cell)\n",
        "      adjusted_cell[\"adjusted_col_start\"] = real_col_index\n",
        "      adjusted_cell[\"adjusted_col_end\"] = (\n",
        "          adjusted_cell[\"adjusted_col_start\"] + adjusted_cell[\"column_span\"])\n",
        "      real_col_index += adjusted_cell[\"column_span\"]\n",
        "      adjusted_row.append(adjusted_cell)\n",
        "    adjusted_table.append(adjusted_row)\n",
        "  return adjusted_table\n",
        "\n",
        "\n",
        "def _get_heuristic_row_headers(adjusted_table, row_index, col_index):\n",
        "  \"\"\"Heuristic to find row headers.\"\"\"\n",
        "  row_headers = []\n",
        "  row = adjusted_table[row_index]\n",
        "  for i in range(0, col_index):\n",
        "    if row[i][\"is_header\"]:\n",
        "      row_headers.append(row[i])\n",
        "  return row_headers\n",
        "\n",
        "\n",
        "def _get_heuristic_col_headers(adjusted_table, row_index, col_index):\n",
        "  \"\"\"Heuristic to find column headers.\"\"\"\n",
        "  adjusted_cell = adjusted_table[row_index][col_index]\n",
        "  adjusted_col_start = adjusted_cell[\"adjusted_col_start\"]\n",
        "  adjusted_col_end = adjusted_cell[\"adjusted_col_end\"]\n",
        "  col_headers = []\n",
        "  for r in range(0, row_index):\n",
        "    row = adjusted_table[r]\n",
        "    for cell in row:\n",
        "      if (cell[\"adjusted_col_start\"] < adjusted_col_end and\n",
        "          cell[\"adjusted_col_end\"] > adjusted_col_start):\n",
        "        if cell[\"is_header\"]:\n",
        "          col_headers.append(cell)\n",
        "\n",
        "  return col_headers\n",
        "\n",
        "\n",
        "def get_highlighted_subtable(table, cell_indices, with_heuristic_headers=False):\n",
        "  \"\"\"Extract out the highlighted part of a table.\"\"\"\n",
        "  highlighted_table = []\n",
        "\n",
        "  adjusted_table = _add_adjusted_col_offsets(table)\n",
        "\n",
        "  for (row_index, col_index) in cell_indices:\n",
        "    cell = table[row_index][col_index]\n",
        "    if with_heuristic_headers:\n",
        "      row_headers = _get_heuristic_row_headers(adjusted_table, row_index,\n",
        "                                               col_index)\n",
        "      col_headers = _get_heuristic_col_headers(adjusted_table, row_index,\n",
        "                                               col_index)\n",
        "    else:\n",
        "      row_headers = []\n",
        "      col_headers = []\n",
        "\n",
        "    highlighted_cell = {\n",
        "        \"cell\": cell,\n",
        "        \"row_headers\": row_headers,\n",
        "        \"col_headers\": col_headers\n",
        "    }\n",
        "    highlighted_table.append(highlighted_cell)\n",
        "\n",
        "  return highlighted_table\n",
        "\n",
        "\n",
        "def linearize_full_table(table, cell_indices, table_page_title,\n",
        "                         table_section_title):\n",
        "  \"\"\"Linearize full table with localized headers and return a string.\"\"\"\n",
        "  table_str = \"\"\n",
        "  if table_page_title:\n",
        "    table_str += \"<page_title> \" + table_page_title + \" </page_title> \"\n",
        "  if table_section_title:\n",
        "    table_str += \"<section_title> \" + table_section_title + \" </section_title> \"\n",
        "\n",
        "  table_str += \"<table> \"\n",
        "  adjusted_table = _add_adjusted_col_offsets(table)\n",
        "  for r_index, row in enumerate(table):\n",
        "    row_str = \"<row> \"\n",
        "    for c_index, col in enumerate(row):\n",
        "\n",
        "      row_headers = _get_heuristic_row_headers(adjusted_table, r_index, c_index)\n",
        "      col_headers = _get_heuristic_col_headers(adjusted_table, r_index, c_index)\n",
        "\n",
        "      # Distinguish between highlighted and non-highlighted cells.\n",
        "      if [r_index, c_index] in cell_indices:\n",
        "        start_cell_marker = \"<highlighted_cell> \"\n",
        "        end_cell_marker = \"</highlighted_cell> \"\n",
        "      else:\n",
        "        start_cell_marker = \"<cell> \"\n",
        "        end_cell_marker = \"</cell> \"\n",
        "\n",
        "      # The value of the cell.\n",
        "      item_str = start_cell_marker + col[\"value\"] + \" \"\n",
        "\n",
        "      # All the column headers associated with this cell.\n",
        "      for col_header in col_headers:\n",
        "        item_str += \"<col_header> \" + col_header[\"value\"] + \" </col_header> \"\n",
        "\n",
        "      # All the row headers associated with this cell.\n",
        "      for row_header in row_headers:\n",
        "        item_str += \"<row_header> \" + row_header[\"value\"] + \" </row_header> \"\n",
        "\n",
        "      item_str += end_cell_marker\n",
        "      row_str += item_str\n",
        "\n",
        "    row_str += \"</row> \"\n",
        "    table_str += row_str\n",
        "\n",
        "  table_str += \"</table>\"\n",
        "  if cell_indices:\n",
        "    assert \"<highlighted_cell>\" in table_str\n",
        "  return table_str\n",
        "\n",
        "\n",
        "def linearize_subtable(subtable, table_page_title, table_section_title):\n",
        "  \"\"\"Linearize the highlighted subtable and return a string of its contents.\"\"\"\n",
        "  table_str = \"\"\n",
        "  if table_page_title:\n",
        "    table_str += \"<page_title> \" + table_page_title + \" </page_title> \"\n",
        "  if table_section_title:\n",
        "    table_str += \"<section_title> \" + table_section_title + \" </section_title> \"\n",
        "  table_str += \"<table> \"\n",
        "\n",
        "  for item in subtable:\n",
        "    cell = item[\"cell\"]\n",
        "    row_headers = item[\"row_headers\"]\n",
        "    col_headers = item[\"col_headers\"]\n",
        "\n",
        "    # The value of the cell.\n",
        "    item_str = \"<cell> \" + cell[\"value\"] + \" \"\n",
        "\n",
        "    # All the column headers associated with this cell.\n",
        "    for col_header in col_headers:\n",
        "      item_str += \"<col_header> \" + col_header[\"value\"] + \" </col_header> \"\n",
        "\n",
        "    # All the row headers associated with this cell.\n",
        "    for row_header in row_headers:\n",
        "      item_str += \"<row_header> \" + row_header[\"value\"] + \" </row_header> \"\n",
        "\n",
        "    item_str += \"</cell> \"\n",
        "    table_str += item_str\n",
        "\n",
        "  table_str += \"</table>\"\n",
        "  return table_str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f6aJiuM5WoZ"
      },
      "source": [
        "## **1.3 Model & tokenizer setting for generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdTqCtKF5VyD",
        "outputId": "2d26df05-e33d-476a-87c4-846893965cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU Index: 0\n",
            "Current GPU Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current GPU Index:\", torch.cuda.current_device())\n",
        "    print(\"Current GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411,
          "referenced_widgets": [
            "0f66ceaa9eba4829bca33291548758e5",
            "8e78f9d072d541c1ba006f2d6f7d5478",
            "f97af23c9066435ba21871d984ab7761",
            "4bf4d09f033047309d0529ae9f89b6c2",
            "c392b6ebce064497b100d4127a93291e",
            "66ede5d1198f431cb4c9bfe29dea55df",
            "38b4955632d84b96a6c1d3b8569ebd0c",
            "541ae4d5999a4473a1318a8647408e4a",
            "901b70d5331e4113b8ec242380336cff",
            "a0183c6628444ce3a45a2b141157521e",
            "719b5eef8e3842238561241b1ecca891",
            "89de1c26e5c84f31bd3082d921925efb",
            "07459caabbc24080ae8048ece14f7826",
            "01485705da9d4ee6851fb2aea775ff13",
            "72c096a27e2e417999376581d39a9bd2",
            "93219f9ea283476aae653143a1b64159",
            "268b3ebf53bf4bf39c41ea5b13837f54",
            "6250dd6c38aa42f3915176ee83bc1246",
            "4804d14635794566a85baeb8f013c06e",
            "1f9c0da2dddc4420b291b94e1592d39b",
            "c636822d4b9f48bf9fa5305cbc61f2c2",
            "07a74c284c0e4c8297649037979c7f23",
            "c15667eac4a74d47ae934de5aa13464c",
            "7f34ce27a51f48a3a8d578c5756b2e26",
            "00c34f57ce784c6e85346169f35dd05b",
            "199b507a5eb143acb18ae3bf3186bc6a",
            "eb329434cf16419abf0dad5691d07938",
            "0362fc22116947a6ad1f01cd78c0597c",
            "c75380c383944753bc7e88c55ffd9307",
            "50b09d3873894bdaabb6e2688ee9fb95",
            "3396b0f2c34446908a14bf28e003fb5d",
            "f3d4ca5535de4078b89a58548c0b7113",
            "7e79348f13bd4e2a872957dc4a24347b"
          ]
        },
        "id": "JIY8Lq9q567J",
        "outputId": "bbb0c7ff-fb6e-4490-e920-d0158cc86369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f66ceaa9eba4829bca33291548758e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89de1c26e5c84f31bd3082d921925efb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c15667eac4a74d47ae934de5aa13464c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5Model\n",
        "\n",
        "# Pre-Trained T5 Tokenizer\n",
        "tokenizer=T5Tokenizer.from_pretrained('t5-base')\n",
        "# Add Special Tokens: Table Tags\n",
        "tokenizer.add_special_tokens({\n",
        "    'additional_special_tokens': [\n",
        "        '<page_title>',\n",
        "        '</page_title>',\n",
        "        '<section_title>',\n",
        "        '</section_title>',\n",
        "        '<table>',\n",
        "        '</table>',\n",
        "        '<cell>',\n",
        "        '</cell>',\n",
        "        '<col_header>',\n",
        "        '</col_header>',\n",
        "        '<row_header>',\n",
        "        '</row_header>'\n",
        "    ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-p4frr5z5_wi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToTToDataset(Dataset):\n",
        "    def __init__(self, path_data, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "        self.attention_mask = []\n",
        "\n",
        "        # Load Dataset\n",
        "        with open(path_data, 'r') as f:\n",
        "            dataset = f.read().splitlines()\n",
        "\n",
        "        for _data in dataset:\n",
        "            data = json.loads(_data)\n",
        "\n",
        "            # Preprocess\n",
        "            subtable = get_highlighted_subtable(table=data['table'], cell_indices=data['highlighted_cells'], with_heuristic_headers=True)\n",
        "            cells_linearized = linearize_subtable(subtable=subtable, table_page_title=data['table_page_title'], table_section_title=data['table_section_title'])\n",
        "\n",
        "            # Encode\n",
        "            encoded_dict = tokenizer.encode_plus(cells_linearized, max_length=512, truncation=True, padding=\"max_length\", return_attention_mask=True)\n",
        "            self.data.append(encoded_dict['input_ids'])\n",
        "            self.attention_mask.append(encoded_dict['attention_mask'])\n",
        "            self.label.append(tokenizer.encode(data['sentence_annotations'][0]['final_sentence'], max_length=512, truncation=True))\n",
        "\n",
        "        print(len(self.data), 'datas')\n",
        "        print(len(self.label), 'labels')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(self.data[idx], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
        "            'labels': torch.tensor(self.label[idx], dtype=torch.long)\n",
        "        }\n",
        "        return item\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "79adb668d659477c9ada38e1da7ac118",
            "cd891b1710b94f63975641b2a8e7e3a4",
            "79e0566b5cab4697aec84d85e0497406",
            "3bbe2ed116d941feacf29624162a2cc9",
            "43bb09c280ee4167a5c9289704a77156",
            "cc6f7222e64b4c099c04d32d730b4be2",
            "2a8cf69e1ecb4752b62932163a79ea31",
            "3d4b1d19bcac48bdadeb74ac38e28643",
            "836724f6324c4da5ac1ddc3a10eb7e7b",
            "1ba2626f427e4bf289f47d92869fd1c3",
            "7d6a534912594ff5968c231f69825982",
            "cb57089c9ed041d2b6d1941136ad709c",
            "fc20e6fe1a974a31a334a32c694fc350",
            "96e5d7e8910f468fad2fcf71ab727a17",
            "0c5db13b757a4aa999b561945c7dd776",
            "3cd627c2cb424360b83f8ac55ced4ce2",
            "c32c105c5b5549319706bb757845de53",
            "c3dea39ad17d4a60aaed237f39681383",
            "75d3e1938ff74b08aeb54911e9e221cc",
            "cece50a899ee4de296ad0c50b26b848b",
            "634aade8ba92404cb7e119cbe336abd8",
            "eda167e2071a463580cc18d19bb27c8a"
          ]
        },
        "id": "CGVtn1O27lk7",
        "outputId": "b223efc9-0441-40d2-f294-6112ea17672b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79adb668d659477c9ada38e1da7ac118"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb57089c9ed041d2b6d1941136ad709c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32112, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Pre-Trained T5 Model\n",
        "model=T5ForConditionalGeneration.from_pretrained('t5-base').to(device)\n",
        "# Resize PLM's Embedding Layer\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlSu2XmmF_9X",
        "outputId": "83d963cd-fb70-4690-8eaf-78b4478e3cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7700 datas\n",
            "7700 labels\n"
          ]
        }
      ],
      "source": [
        "dataset_dev = ToTToDataset(path_data=\"/content/drive/MyDrive/ToTTo_data/totto_dev_data.jsonl\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Zgqvln6p546a"
      },
      "outputs": [],
      "source": [
        "# batch_size = 24\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pdbKYj88IRVJ"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# Data collator 인스턴스 생성\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRMpHagaIGOA",
        "outputId": "0c37d3a3-a6ca-4324-af93-37a77b3ab32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 512])\n",
            "torch.Size([8, 46])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# DataLoader 생성\n",
        "dataloader = DataLoader(dataset_dev, batch_size=8, collate_fn=data_collator)\n",
        "\n",
        "# 배치 데이터 형식 확인\n",
        "for batch in dataloader:\n",
        "    print(batch.keys())\n",
        "    print(batch['input_ids'].shape)\n",
        "    print(batch['attention_mask'].shape)\n",
        "    if 'labels' in batch:\n",
        "        print(batch['labels'].shape)\n",
        "    break  # 첫 번째 배치만 확인하고 반복 중지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DfaTcPtTogF",
        "outputId": "883aa90e-3483-43d6-afca-7107f7825020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "from transformers import T5Config\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "tokenizer.add_special_tokens({\n",
        "    'additional_special_tokens': [\n",
        "        '<page_title>',\n",
        "        '</page_title>',\n",
        "        '<section_title>',\n",
        "        '</section_title>',\n",
        "        '<table>',\n",
        "        '</table>',\n",
        "        '<cell>',\n",
        "        '</cell>',\n",
        "        '<col_header>',\n",
        "        '</col_header>',\n",
        "        '<row_header>',\n",
        "        '</row_header>'\n",
        "    ]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omesc3RjD0J2",
        "outputId": "47a7dd24-f0fc-44d3-cc32-b62f789c5995"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32112, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "model=T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mTAIL1laD0Nr"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    task_type=\"SEQ_2_SEQ_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.01,\n",
        ")\n",
        "\n",
        "# LoRA T5-small model\n",
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJHoIkc-D5hB",
        "outputId": "e18d0632-a266-4312-876a-658a11fc0692"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32112, 768)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32112, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32112, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): lora.Linear(\n",
              "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.01, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=32112, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model_path='/content/drive/MyDrive/ToTTo_T5-base_LoRA/model/epoch3/T5-base_LoRA_Fine-Tuning_lr0.001_epoch3.pth'\n",
        "\n",
        "# 저장된 state_dict 로드\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# 모델을 평가 모드로 설정\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pSg0kIqAsMp"
      },
      "source": [
        "### **Text Genration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNBX2CKVIy9X",
        "outputId": "e86b9355-566e-41cf-978f-30bbc55209fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 generated\n",
            "1600 generated\n",
            "2400 generated\n",
            "3200 generated\n",
            "4000 generated\n",
            "4800 generated\n",
            "5600 generated\n",
            "6400 generated\n",
            "7200 generated\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "# Generation\n",
        "if os.path.exists('/content/drive/MyDrive/ToTTo_T5-base_LoRA/generation_text/generation_dev_epoch3.txt'):\n",
        "    os.remove('/content/drive/MyDrive/ToTTo_T5-base_LoRA/generation_text/generation_dev_epoch3.txt')\n",
        "f=open('/content/drive/MyDrive/ToTTo_T5-base_LoRA/generation_text/generation_dev_epoch3.txt', 'a')\n",
        "\n",
        "count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        count += 1\n",
        "        if (count) % 100 == 0:\n",
        "            print(batch_size*(count), 'generated')\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # Generate sequences\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=300,\n",
        "            num_beams=5,\n",
        "            early_stopping=True,\n",
        "\n",
        "        )\n",
        "\n",
        "        generated_sentences = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "        for sentence in generated_sentences:\n",
        "            f.write(sentence + '\\n')\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7NdVhQ093d2"
      },
      "source": [
        "## **2.1 Evaluation repository**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV-hFpSi6pez",
        "outputId": "f6be4119-1d5c-4015-eee7-d1af4486ab2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'language_repo'...\n",
            "remote: Enumerating objects: 3851, done.\u001b[K\n",
            "remote: Counting objects: 100% (835/835), done.\u001b[K\n",
            "remote: Compressing objects: 100% (474/474), done.\u001b[K\n",
            "remote: Total 3851 (delta 404), reused 676 (delta 350), pack-reused 3016\u001b[K\n",
            "Receiving objects: 100% (3851/3851), 6.24 MiB | 18.17 MiB/s, done.\n",
            "Resolving deltas: 100% (2181/2181), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Song-Joo-Young/language.git language_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_HQ7eKMqjNM",
        "outputId": "91b680d0-83c6-4590-98b0-233cd22a4ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/google-research/bleurt.git\n",
            "  Cloning https://github.com/google-research/bleurt.git to /tmp/pip-req-build-aihrmi1t\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-research/bleurt.git /tmp/pip-req-build-aihrmi1t\n",
            "  Resolved https://github.com/google-research/bleurt.git to commit cebe7e6f996b40910cfaa520a63db47807e3bf5c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.11.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (2.15.0)\n",
            "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (0.1.99)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2023.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->BLEURT==0.0.2) (3.2.2)\n",
            "Building wheels for collected packages: BLEURT\n",
            "  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456765 sha256=2df24d0d3eb01df3360a4a906b75a245f904751fcb3707b832a6bf6473bc31e9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rb64_d1h/wheels/64/f4/2c/509a6c31b8ebde891a81029fd94f199b1b92f0e7cfc20d417a\n",
            "Successfully built BLEURT\n",
            "Installing collected packages: BLEURT\n",
            "Successfully installed BLEURT-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/google-research/bleurt.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYAAn83HKXDQ"
      },
      "source": [
        "## **2.2 Setting Up the Directory & Requirement for BLEURT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l2bNnSVwcoI",
        "outputId": "37a12494-c82c-4f13-a7ae-b93cca8f52b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/language_repo\n"
          ]
        }
      ],
      "source": [
        "%cd language_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhIOhvHoyobE",
        "outputId": "9c65dbcc-5df1-4fff-d09b-be7df767205c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-11 03:21:36--  https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.136.207, 142.250.148.207, 209.85.200.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.136.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2140294207 (2.0G) [application/octet-stream]\n",
            "Saving to: ‘BLEURT-20.zip’\n",
            "\n",
            "BLEURT-20.zip       100%[===================>]   1.99G  83.6MB/s    in 24s     \n",
            "\n",
            "2024-02-11 03:22:00 (86.7 MB/s) - ‘BLEURT-20.zip’ saved [2140294207/2140294207]\n",
            "\n",
            "--2024-02-11 03:22:00--  http://./\n",
            "Resolving . (.)... failed: No address associated with hostname.\n",
            "wget: unable to resolve host address ‘.’\n",
            "FINISHED --2024-02-11 03:22:00--\n",
            "Total wall clock time: 24s\n",
            "Downloaded: 1 files, 2.0G in 24s (86.7 MB/s)\n",
            "Archive:  BLEURT-20.zip\n",
            "   creating: BLEURT-20/\n",
            "  inflating: BLEURT-20/bert_config.json  \n",
            "  inflating: BLEURT-20/saved_model.pb  \n",
            "   creating: BLEURT-20/variables/\n",
            "  inflating: BLEURT-20/variables/variables.index  \n",
            "  inflating: BLEURT-20/variables/variables.data-00000-of-00001  \n",
            "  inflating: BLEURT-20/sent_piece.vocab  \n",
            "  inflating: BLEURT-20/bleurt_config.json  \n",
            "  inflating: BLEURT-20/sent_piece.model  \n"
          ]
        }
      ],
      "source": [
        "# Downloads the BLEURT-base checkpoint.\n",
        "! wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip .\n",
        "! unzip BLEURT-20.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HklX0jsE9w52",
        "outputId": "f3b5a5ec-8881-4dc6-e451-5fc594980e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from -r language/totto/eval_requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r language/totto/eval_requirements.txt (line 2)) (7.4.4)\n",
            "Collecting sacrebleu (from -r language/totto/eval_requirements.txt (line 3))\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r language/totto/eval_requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from -r language/totto/eval_requirements.txt (line 5)) (0.42.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r language/totto/eval_requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->-r language/totto/eval_requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r language/totto/eval_requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r language/totto/eval_requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r language/totto/eval_requirements.txt (line 2)) (2.0.1)\n",
            "Collecting portalocker (from sacrebleu->-r language/totto/eval_requirements.txt (line 3))\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r language/totto/eval_requirements.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r language/totto/eval_requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r language/totto/eval_requirements.txt (line 3)) (1.23.5)\n",
            "Collecting colorama (from sacrebleu->-r language/totto/eval_requirements.txt (line 3))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r language/totto/eval_requirements.txt (line 3)) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.0\n"
          ]
        }
      ],
      "source": [
        "! pip3 install -r language/totto/eval_requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxR7vjuSKiXR"
      },
      "source": [
        "#### **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmoh4EBiTNcA",
        "outputId": "7f324368-3e20-43f6-bf61-a921024fae4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running with the following variables:\n",
            "PREDICTION_PATH   : /content/drive/MyDrive/ToTTo_T5-base_LoRA/generation_text/generation_dev_epoch3.txt\n",
            "TARGET_PATH       : /content/drive/MyDrive/ToTTo_data/totto_dev_data.jsonl \n",
            "BLEURT_CKPT       : BLEURT-20 \n",
            "OUTPUT_DIR        : temp\n",
            "MODE              : test\n",
            "Creating Output directory.\n",
            "Cloning moses for BLEU script.\n",
            "Cloning into 'temp/mosesdecoder'...\n",
            "remote: Enumerating objects: 148103, done.\u001b[K\n",
            "remote: Counting objects: 100% (531/531), done.\u001b[K\n",
            "remote: Compressing objects: 100% (234/234), done.\u001b[K\n",
            "remote: Total 148103 (delta 329), reused 445 (delta 293), pack-reused 147572\u001b[K\n",
            "Receiving objects: 100% (148103/148103), 129.88 MiB | 14.51 MiB/s, done.\n",
            "Resolving deltas: 100% (114355/114355), done.\n",
            "Writing references.\n",
            "Writing tables in PARENT format.\n",
            "Preparing predictions.\n",
            "Writing predictions.\n",
            "Running detokenizers.\n",
            "======== EVALUATE OVERALL ========\n",
            "Computing BLEU (overall)\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 44.7,\n",
            " \"signature\": \"nrefs:3|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.0\",\n",
            " \"verbose_score\": \"76.1/52.2/39.1/30.2 (BP = 0.962 ratio = 0.962 hyp_len = 124544 ref_len = 129407)\",\n",
            " \"nrefs\": \"3\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.4.0\"\n",
            "}\n",
            "\u001b[0mComputing PARENT (overall)\n",
            "Evaluated 7700 examples.\n",
            "Precision = 81.09 Recall = 48.00 F-score = 56.08\n",
            "Computing BLEURT score\n",
            "2024-02-11 03:27:32.272040: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-11 03:27:32.272092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-11 03:27:32.273456: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-11 03:27:33.625926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:tensorflow:Reading checkpoint BLEURT-20.\n",
            "I0211 03:27:36.616549 139130042163200 score.py:160] Reading checkpoint BLEURT-20.\n",
            "INFO:tensorflow:Config file found, reading.\n",
            "I0211 03:27:36.619592 139130042163200 checkpoint.py:91] Config file found, reading.\n",
            "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
            "I0211 03:27:36.620045 139130042163200 checkpoint.py:95] Will load checkpoint BLEURT-20\n",
            "INFO:tensorflow:Loads full paths and checks that files exists.\n",
            "I0211 03:27:36.620190 139130042163200 checkpoint.py:97] Loads full paths and checks that files exists.\n",
            "INFO:tensorflow:... name:BLEURT-20\n",
            "I0211 03:27:36.620270 139130042163200 checkpoint.py:101] ... name:BLEURT-20\n",
            "INFO:tensorflow:... bert_config_file:bert_config.json\n",
            "I0211 03:27:36.620342 139130042163200 checkpoint.py:101] ... bert_config_file:bert_config.json\n",
            "INFO:tensorflow:... max_seq_length:512\n",
            "I0211 03:27:36.620454 139130042163200 checkpoint.py:101] ... max_seq_length:512\n",
            "INFO:tensorflow:... vocab_file:None\n",
            "I0211 03:27:36.620610 139130042163200 checkpoint.py:101] ... vocab_file:None\n",
            "INFO:tensorflow:... do_lower_case:None\n",
            "I0211 03:27:36.620678 139130042163200 checkpoint.py:101] ... do_lower_case:None\n",
            "INFO:tensorflow:... sp_model:sent_piece\n",
            "I0211 03:27:36.620749 139130042163200 checkpoint.py:101] ... sp_model:sent_piece\n",
            "INFO:tensorflow:... dynamic_seq_length:True\n",
            "I0211 03:27:36.620865 139130042163200 checkpoint.py:101] ... dynamic_seq_length:True\n",
            "INFO:tensorflow:Creating BLEURT scorer.\n",
            "I0211 03:27:36.620970 139130042163200 score.py:167] Creating BLEURT scorer.\n",
            "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
            "I0211 03:27:36.621040 139130042163200 tokenizers.py:79] Creating SentencePiece tokenizer.\n",
            "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
            "I0211 03:27:36.621101 139130042163200 tokenizers.py:58] Creating SentencePiece tokenizer.\n",
            "INFO:tensorflow:Will load model: BLEURT-20/sent_piece.model.\n",
            "I0211 03:27:36.621161 139130042163200 tokenizers.py:60] Will load model: BLEURT-20/sent_piece.model.\n",
            "INFO:tensorflow:SentencePiece tokenizer created.\n",
            "I0211 03:27:37.285462 139130042163200 tokenizers.py:64] SentencePiece tokenizer created.\n",
            "INFO:tensorflow:Creating Eager Mode predictor.\n",
            "I0211 03:27:37.285742 139130042163200 score.py:56] Creating Eager Mode predictor.\n",
            "INFO:tensorflow:Loading model.\n",
            "I0211 03:27:37.285832 139130042163200 score.py:61] Loading model.\n",
            "2024-02-11 03:27:38.637836: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0211 03:27:54.914488 139130042163200 load.py:1084] Fingerprint not found. Saved model loading will continue.\n",
            "I0211 03:27:54.920538 139130042163200 load.py:1103] path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
            "INFO:tensorflow:BLEURT initialized.\n",
            "I0211 03:27:54.971365 139130042163200 score.py:173] BLEURT initialized.\n",
            "Evaluated 7700 examples.\n",
            "Average BLEURT score = 0.6530\n",
            "======== EVALUATE OVERLAP SUBSET ========\n",
            "Computing BLEU (overlap subset)\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 51.6,\n",
            " \"signature\": \"nrefs:3|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.0\",\n",
            " \"verbose_score\": \"79.7/58.3/46.3/37.5 (BP = 0.968 ratio = 0.969 hyp_len = 60871 ref_len = 62832)\",\n",
            " \"nrefs\": \"3\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.4.0\"\n",
            "}\n",
            "\u001b[0mComputing PARENT (overlap subset)\n",
            "Evaluated 3784 examples.\n",
            "Precision = 82.93 Recall = 51.67 F-score = 59.82\n",
            "Computing BLEURT score\n",
            "2024-02-11 04:55:38.429110: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-11 04:55:38.429158: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-11 04:55:38.430468: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-11 04:55:40.378773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:tensorflow:Reading checkpoint BLEURT-20.\n",
            "I0211 04:55:43.933832 133263755321344 score.py:160] Reading checkpoint BLEURT-20.\n",
            "INFO:tensorflow:Config file found, reading.\n",
            "I0211 04:55:43.934140 133263755321344 checkpoint.py:91] Config file found, reading.\n",
            "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
            "I0211 04:55:43.935096 133263755321344 checkpoint.py:95] Will load checkpoint BLEURT-20\n",
            "INFO:tensorflow:Loads full paths and checks that files exists.\n",
            "I0211 04:55:43.935228 133263755321344 checkpoint.py:97] Loads full paths and checks that files exists.\n",
            "INFO:tensorflow:... name:BLEURT-20\n",
            "I0211 04:55:43.935302 133263755321344 checkpoint.py:101] ... name:BLEURT-20\n",
            "INFO:tensorflow:... bert_config_file:bert_config.json\n",
            "I0211 04:55:43.935365 133263755321344 checkpoint.py:101] ... bert_config_file:bert_config.json\n",
            "INFO:tensorflow:... max_seq_length:512\n",
            "I0211 04:55:43.935456 133263755321344 checkpoint.py:101] ... max_seq_length:512\n",
            "INFO:tensorflow:... vocab_file:None\n",
            "I0211 04:55:43.935524 133263755321344 checkpoint.py:101] ... vocab_file:None\n",
            "INFO:tensorflow:... do_lower_case:None\n",
            "I0211 04:55:43.935583 133263755321344 checkpoint.py:101] ... do_lower_case:None\n",
            "INFO:tensorflow:... sp_model:sent_piece\n",
            "I0211 04:55:43.935639 133263755321344 checkpoint.py:101] ... sp_model:sent_piece\n",
            "INFO:tensorflow:... dynamic_seq_length:True\n",
            "I0211 04:55:43.935731 133263755321344 checkpoint.py:101] ... dynamic_seq_length:True\n",
            "INFO:tensorflow:Creating BLEURT scorer.\n",
            "I0211 04:55:43.935806 133263755321344 score.py:167] Creating BLEURT scorer.\n",
            "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
            "I0211 04:55:43.935868 133263755321344 tokenizers.py:79] Creating SentencePiece tokenizer.\n",
            "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
            "I0211 04:55:43.935935 133263755321344 tokenizers.py:58] Creating SentencePiece tokenizer.\n",
            "INFO:tensorflow:Will load model: BLEURT-20/sent_piece.model.\n",
            "I0211 04:55:43.936011 133263755321344 tokenizers.py:60] Will load model: BLEURT-20/sent_piece.model.\n",
            "INFO:tensorflow:SentencePiece tokenizer created.\n",
            "I0211 04:55:44.472531 133263755321344 tokenizers.py:64] SentencePiece tokenizer created.\n",
            "INFO:tensorflow:Creating Eager Mode predictor.\n",
            "I0211 04:55:44.472789 133263755321344 score.py:56] Creating Eager Mode predictor.\n",
            "INFO:tensorflow:Loading model.\n",
            "I0211 04:55:44.472889 133263755321344 score.py:61] Loading model.\n",
            "2024-02-11 04:55:45.821107: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0211 04:55:58.254476 133263755321344 load.py:1084] Fingerprint not found. Saved model loading will continue.\n",
            "I0211 04:55:58.254703 133263755321344 load.py:1103] path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
            "INFO:tensorflow:BLEURT initialized.\n",
            "I0211 04:55:58.296039 133263755321344 score.py:173] BLEURT initialized.\n",
            "Evaluated 3784 examples.\n",
            "Average BLEURT score = 0.6893\n",
            "======== EVALUATE NON-OVERLAP SUBSET ========\n",
            "Computing BLEU (non-overlap subset)\n",
            "{\n",
            " \"name\": \"BLEU\",\n",
            " \"score\": 38.0,\n",
            " \"signature\": \"nrefs:3|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.0\",\n",
            " \"verbose_score\": \"72.7/46.4/32.1/23.2 (BP = 0.955 ratio = 0.956 hyp_len = 63673 ref_len = 66575)\",\n",
            " \"nrefs\": \"3\",\n",
            " \"case\": \"mixed\",\n",
            " \"eff\": \"no\",\n",
            " \"tok\": \"13a\",\n",
            " \"smooth\": \"exp\",\n",
            " \"version\": \"2.4.0\"\n",
            "}\n",
            "\u001b[0mComputing PARENT (non-overlap subset)\n",
            "Evaluated 3916 examples.\n",
            "Precision = 79.30 Recall = 44.46 F-score = 52.47\n",
            "Computing BLEURT score\n",
            "2024-02-11 05:40:27.287004: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-11 05:40:27.287054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-11 05:40:27.289881: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-11 05:40:29.182683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:tensorflow:Reading checkpoint BLEURT-20.\n",
            "I0211 05:40:32.541930 132873639944192 score.py:160] Reading checkpoint BLEURT-20.\n",
            "INFO:tensorflow:Config file found, reading.\n",
            "I0211 05:40:32.542309 132873639944192 checkpoint.py:91] Config file found, reading.\n",
            "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
            "I0211 05:40:32.543529 132873639944192 checkpoint.py:95] Will load checkpoint BLEURT-20\n",
            "INFO:tensorflow:Loads full paths and checks that files exists.\n",
            "I0211 05:40:32.543738 132873639944192 checkpoint.py:97] Loads full paths and checks that files exists.\n",
            "INFO:tensorflow:... name:BLEURT-20\n",
            "I0211 05:40:32.543837 132873639944192 checkpoint.py:101] ... name:BLEURT-20\n",
            "INFO:tensorflow:... bert_config_file:bert_config.json\n",
            "I0211 05:40:32.543911 132873639944192 checkpoint.py:101] ... bert_config_file:bert_config.json\n",
            "INFO:tensorflow:... max_seq_length:512\n",
            "I0211 05:40:32.544046 132873639944192 checkpoint.py:101] ... max_seq_length:512\n",
            "INFO:tensorflow:... vocab_file:None\n",
            "I0211 05:40:32.544126 132873639944192 checkpoint.py:101] ... vocab_file:None\n",
            "INFO:tensorflow:... do_lower_case:None\n",
            "I0211 05:40:32.544205 132873639944192 checkpoint.py:101] ... do_lower_case:None\n",
            "INFO:tensorflow:... sp_model:sent_piece\n",
            "I0211 05:40:32.544274 132873639944192 checkpoint.py:101] ... sp_model:sent_piece\n",
            "INFO:tensorflow:... dynamic_seq_length:True\n",
            "I0211 05:40:32.544380 132873639944192 checkpoint.py:101] ... dynamic_seq_length:True\n",
            "INFO:tensorflow:Creating BLEURT scorer.\n",
            "I0211 05:40:32.544461 132873639944192 score.py:167] Creating BLEURT scorer.\n",
            "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
            "I0211 05:40:32.544532 132873639944192 tokenizers.py:79] Creating SentencePiece tokenizer.\n",
            "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
            "I0211 05:40:32.544603 132873639944192 tokenizers.py:58] Creating SentencePiece tokenizer.\n",
            "INFO:tensorflow:Will load model: BLEURT-20/sent_piece.model.\n",
            "I0211 05:40:32.544671 132873639944192 tokenizers.py:60] Will load model: BLEURT-20/sent_piece.model.\n",
            "INFO:tensorflow:SentencePiece tokenizer created.\n",
            "I0211 05:40:33.351626 132873639944192 tokenizers.py:64] SentencePiece tokenizer created.\n",
            "INFO:tensorflow:Creating Eager Mode predictor.\n",
            "I0211 05:40:33.351944 132873639944192 score.py:56] Creating Eager Mode predictor.\n",
            "INFO:tensorflow:Loading model.\n",
            "I0211 05:40:33.352091 132873639944192 score.py:61] Loading model.\n",
            "2024-02-11 05:40:34.820916: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0211 05:40:46.107680 132873639944192 load.py:1084] Fingerprint not found. Saved model loading will continue.\n",
            "I0211 05:40:46.107971 132873639944192 load.py:1103] path_and_singleprint metric could not be logged. Saved model loading will continue.\n",
            "INFO:tensorflow:BLEURT initialized.\n",
            "I0211 05:40:46.170565 132873639944192 score.py:173] BLEURT initialized.\n",
            "Evaluated 3916 examples.\n",
            "Average BLEURT score = 0.6180\n"
          ]
        }
      ],
      "source": [
        "# Epoch 3\n",
        "! bash language/totto/totto_eval.sh --prediction_path /content/drive/MyDrive/ToTTo_T5-base_LoRA/generation_text/generation_dev_epoch3.txt --target_path /content/drive/MyDrive/ToTTo_data/totto_dev_data.jsonl --bleurt_ckpt BLEURT-20"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f66ceaa9eba4829bca33291548758e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e78f9d072d541c1ba006f2d6f7d5478",
              "IPY_MODEL_f97af23c9066435ba21871d984ab7761",
              "IPY_MODEL_4bf4d09f033047309d0529ae9f89b6c2"
            ],
            "layout": "IPY_MODEL_c392b6ebce064497b100d4127a93291e"
          }
        },
        "8e78f9d072d541c1ba006f2d6f7d5478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66ede5d1198f431cb4c9bfe29dea55df",
            "placeholder": "​",
            "style": "IPY_MODEL_38b4955632d84b96a6c1d3b8569ebd0c",
            "value": "spiece.model: 100%"
          }
        },
        "f97af23c9066435ba21871d984ab7761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_541ae4d5999a4473a1318a8647408e4a",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_901b70d5331e4113b8ec242380336cff",
            "value": 791656
          }
        },
        "4bf4d09f033047309d0529ae9f89b6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0183c6628444ce3a45a2b141157521e",
            "placeholder": "​",
            "style": "IPY_MODEL_719b5eef8e3842238561241b1ecca891",
            "value": " 792k/792k [00:00&lt;00:00, 7.97MB/s]"
          }
        },
        "c392b6ebce064497b100d4127a93291e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ede5d1198f431cb4c9bfe29dea55df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b4955632d84b96a6c1d3b8569ebd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "541ae4d5999a4473a1318a8647408e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901b70d5331e4113b8ec242380336cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0183c6628444ce3a45a2b141157521e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719b5eef8e3842238561241b1ecca891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89de1c26e5c84f31bd3082d921925efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07459caabbc24080ae8048ece14f7826",
              "IPY_MODEL_01485705da9d4ee6851fb2aea775ff13",
              "IPY_MODEL_72c096a27e2e417999376581d39a9bd2"
            ],
            "layout": "IPY_MODEL_93219f9ea283476aae653143a1b64159"
          }
        },
        "07459caabbc24080ae8048ece14f7826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_268b3ebf53bf4bf39c41ea5b13837f54",
            "placeholder": "​",
            "style": "IPY_MODEL_6250dd6c38aa42f3915176ee83bc1246",
            "value": "tokenizer.json: 100%"
          }
        },
        "01485705da9d4ee6851fb2aea775ff13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4804d14635794566a85baeb8f013c06e",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f9c0da2dddc4420b291b94e1592d39b",
            "value": 1389353
          }
        },
        "72c096a27e2e417999376581d39a9bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c636822d4b9f48bf9fa5305cbc61f2c2",
            "placeholder": "​",
            "style": "IPY_MODEL_07a74c284c0e4c8297649037979c7f23",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 7.86MB/s]"
          }
        },
        "93219f9ea283476aae653143a1b64159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268b3ebf53bf4bf39c41ea5b13837f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6250dd6c38aa42f3915176ee83bc1246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4804d14635794566a85baeb8f013c06e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9c0da2dddc4420b291b94e1592d39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c636822d4b9f48bf9fa5305cbc61f2c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a74c284c0e4c8297649037979c7f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c15667eac4a74d47ae934de5aa13464c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f34ce27a51f48a3a8d578c5756b2e26",
              "IPY_MODEL_00c34f57ce784c6e85346169f35dd05b",
              "IPY_MODEL_199b507a5eb143acb18ae3bf3186bc6a"
            ],
            "layout": "IPY_MODEL_eb329434cf16419abf0dad5691d07938"
          }
        },
        "7f34ce27a51f48a3a8d578c5756b2e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0362fc22116947a6ad1f01cd78c0597c",
            "placeholder": "​",
            "style": "IPY_MODEL_c75380c383944753bc7e88c55ffd9307",
            "value": "config.json: 100%"
          }
        },
        "00c34f57ce784c6e85346169f35dd05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b09d3873894bdaabb6e2688ee9fb95",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3396b0f2c34446908a14bf28e003fb5d",
            "value": 1208
          }
        },
        "199b507a5eb143acb18ae3bf3186bc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d4ca5535de4078b89a58548c0b7113",
            "placeholder": "​",
            "style": "IPY_MODEL_7e79348f13bd4e2a872957dc4a24347b",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 71.6kB/s]"
          }
        },
        "eb329434cf16419abf0dad5691d07938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0362fc22116947a6ad1f01cd78c0597c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c75380c383944753bc7e88c55ffd9307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50b09d3873894bdaabb6e2688ee9fb95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3396b0f2c34446908a14bf28e003fb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3d4ca5535de4078b89a58548c0b7113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e79348f13bd4e2a872957dc4a24347b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79adb668d659477c9ada38e1da7ac118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd891b1710b94f63975641b2a8e7e3a4",
              "IPY_MODEL_79e0566b5cab4697aec84d85e0497406",
              "IPY_MODEL_3bbe2ed116d941feacf29624162a2cc9"
            ],
            "layout": "IPY_MODEL_43bb09c280ee4167a5c9289704a77156"
          }
        },
        "cd891b1710b94f63975641b2a8e7e3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6f7222e64b4c099c04d32d730b4be2",
            "placeholder": "​",
            "style": "IPY_MODEL_2a8cf69e1ecb4752b62932163a79ea31",
            "value": "model.safetensors: 100%"
          }
        },
        "79e0566b5cab4697aec84d85e0497406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d4b1d19bcac48bdadeb74ac38e28643",
            "max": 891646390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_836724f6324c4da5ac1ddc3a10eb7e7b",
            "value": 891646390
          }
        },
        "3bbe2ed116d941feacf29624162a2cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba2626f427e4bf289f47d92869fd1c3",
            "placeholder": "​",
            "style": "IPY_MODEL_7d6a534912594ff5968c231f69825982",
            "value": " 892M/892M [00:06&lt;00:00, 183MB/s]"
          }
        },
        "43bb09c280ee4167a5c9289704a77156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc6f7222e64b4c099c04d32d730b4be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a8cf69e1ecb4752b62932163a79ea31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d4b1d19bcac48bdadeb74ac38e28643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836724f6324c4da5ac1ddc3a10eb7e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ba2626f427e4bf289f47d92869fd1c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6a534912594ff5968c231f69825982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb57089c9ed041d2b6d1941136ad709c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc20e6fe1a974a31a334a32c694fc350",
              "IPY_MODEL_96e5d7e8910f468fad2fcf71ab727a17",
              "IPY_MODEL_0c5db13b757a4aa999b561945c7dd776"
            ],
            "layout": "IPY_MODEL_3cd627c2cb424360b83f8ac55ced4ce2"
          }
        },
        "fc20e6fe1a974a31a334a32c694fc350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c32c105c5b5549319706bb757845de53",
            "placeholder": "​",
            "style": "IPY_MODEL_c3dea39ad17d4a60aaed237f39681383",
            "value": "generation_config.json: 100%"
          }
        },
        "96e5d7e8910f468fad2fcf71ab727a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d3e1938ff74b08aeb54911e9e221cc",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cece50a899ee4de296ad0c50b26b848b",
            "value": 147
          }
        },
        "0c5db13b757a4aa999b561945c7dd776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_634aade8ba92404cb7e119cbe336abd8",
            "placeholder": "​",
            "style": "IPY_MODEL_eda167e2071a463580cc18d19bb27c8a",
            "value": " 147/147 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "3cd627c2cb424360b83f8ac55ced4ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32c105c5b5549319706bb757845de53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3dea39ad17d4a60aaed237f39681383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75d3e1938ff74b08aeb54911e9e221cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cece50a899ee4de296ad0c50b26b848b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "634aade8ba92404cb7e119cbe336abd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda167e2071a463580cc18d19bb27c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}